# CORE ëª¨ë“ˆ ìƒì„¸ ë¬¸ì„œ

**ì‘ì„±ì¼**: 2025-09-27
**ë²„ì „**: LangGraph 0.6.7 ê¸°ì¤€
**í”„ë¡œì íŠ¸**: beta_v003

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#ê°œìš”)
2. [ë””ë ‰í† ë¦¬ êµ¬ì¡°](#ë””ë ‰í† ë¦¬-êµ¬ì¡°)
3. [ëª¨ë“ˆë³„ ìƒì„¸ ë¶„ì„](#ëª¨ë“ˆë³„-ìƒì„¸-ë¶„ì„)
   - [__init__.py](#1-__init__py)
   - [base_agent.py](#2-base_agentpy)
   - [checkpointer.py](#3-checkpointerpy)
   - [config.py](#4-configpy)
   - [context.py](#5-contextpy)
   - [states.py](#6-statespy)
4. [í•µì‹¬ ê°œë…](#í•µì‹¬-ê°œë…)
5. [LangGraph 0.6.7 ì±—ë´‡ ê°œë°œ ê°€ì´ë“œ](#langgraph-067-ì±—ë´‡-ê°œë°œ-ê°€ì´ë“œ)
6. [ì£¼ì˜ì‚¬í•­](#ì£¼ì˜ì‚¬í•­)

---

## ê°œìš”

`backend/service/core/` ëª¨ë“ˆì€ LangGraph 0.6.x Context API ê¸°ë°˜ ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

### ì£¼ìš” ê¸°ëŠ¥
- âœ… LangGraph Context API ì™„ì „ ì§€ì›
- âœ… Stateì™€ Context ëª…í™•í•œ ë¶„ë¦¬
- âœ… AsyncSqliteSaver ê¸°ë°˜ ì²´í¬í¬ì¸íŒ…
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•œ BaseAgent ì¶”ìƒ í´ë˜ìŠ¤
- âœ… ë‹¤ì–‘í•œ State ì •ì˜ (Sales, DataCollection, Analysis, Document)
- âœ… ì‹œìŠ¤í…œ ì „ì—­ ì„¤ì • ê´€ë¦¬

### í˜„ì¬ ìƒíƒœ
- âš ï¸ `BaseAgent` í´ë˜ìŠ¤: ì„ì‹œ ë¹„í™œì„±í™” (__init__.py ë¼ì¸ 22, 45)
- âš ï¸ `get_checkpointer` í•¨ìˆ˜: ì„ì‹œ ë¹„í™œì„±í™” (__init__.py ë¼ì¸ 24, 46)

---

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
backend/service/core/
â”œâ”€â”€ __init__.py           # ëª¨ë“ˆ ê³µê°œ API ì •ì˜
â”œâ”€â”€ base_agent.py         # BaseAgent ì¶”ìƒ í´ë˜ìŠ¤ (325ì¤„)
â”œâ”€â”€ checkpointer.py       # ì²´í¬í¬ì¸íŠ¸ ìœ í‹¸ë¦¬í‹° (94ì¤„)
â”œâ”€â”€ config.py             # ì‹œìŠ¤í…œ ì „ì—­ ì„¤ì • (140ì¤„)
â”œâ”€â”€ context.py            # LangGraph Context ì •ì˜ (206ì¤„)
â””â”€â”€ states.py             # LangGraph State ì •ì˜ (267ì¤„)
```

**ì´ ë¼ì¸ ìˆ˜**: 1,032ì¤„

---

## ëª¨ë“ˆë³„ ìƒì„¸ ë¶„ì„

## 1. __init__.py

### ì—­í• 
core ëª¨ë“ˆì˜ ê³µê°œ APIë¥¼ ì •ì˜í•˜ê³  í•„ìš”í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ìµìŠ¤í¬íŠ¸í•©ë‹ˆë‹¤.

### ìµìŠ¤í¬íŠ¸ í•­ëª©

#### States (ìƒíƒœ ì •ì˜)
```python
from .states import (
    BaseState,              # ê¸°ë³¸ ìƒíƒœ
    SalesState,             # ì˜ì—… ë¶„ì„ ìƒíƒœ
    DataCollectionState,    # ë°ì´í„° ìˆ˜ì§‘ ìƒíƒœ
    AnalysisState,          # ë¶„ì„ ìƒíƒœ
    create_sales_initial_state,  # SalesState ì´ˆê¸°í™” í•¨ìˆ˜
    merge_state_updates,    # ìƒíƒœ ì—…ë°ì´íŠ¸ ë³‘í•© í•¨ìˆ˜
    get_state_summary       # ìƒíƒœ ìš”ì•½ í•¨ìˆ˜
)
```

#### Contexts (ì»¨í…ìŠ¤íŠ¸ ì •ì˜)
```python
from .context import (
    AgentContext,           # ì—ì´ì „íŠ¸ ì»¨í…ìŠ¤íŠ¸
    SubgraphContext,        # ì„œë¸Œê·¸ë˜í”„ ì»¨í…ìŠ¤íŠ¸
    create_agent_context,   # AgentContext ìƒì„± í•¨ìˆ˜
    create_subgraph_context,  # SubgraphContext ìƒì„± í•¨ìˆ˜
    merge_with_config_defaults,  # Config ê¸°ë³¸ê°’ ë³‘í•©
    extract_api_keys_from_env   # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì¶”ì¶œ
)
```

#### Config (ì„¤ì •)
```python
from .config import Config  # ì‹œìŠ¤í…œ ì „ì—­ ì„¤ì • í´ë˜ìŠ¤
```

#### ë¹„í™œì„±í™”ëœ ì»´í¬ë„ŒíŠ¸
```python
# from .base_agent import BaseAgent  # ë¼ì¸ 22 - ì„ì‹œ ë¹„í™œì„±í™”
# from .checkpointer import get_checkpointer  # ë¼ì¸ 24 - ì„ì‹œ ë¹„í™œì„±í™”
```

---

## 2. base_agent.py

### ê°œìš”
LangGraph 0.6.x Context APIë¥¼ ì™„ì „íˆ ì§€ì›í•˜ëŠ” ì—ì´ì „íŠ¸ ì¶”ìƒ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

### í´ë˜ìŠ¤: `BaseAgent`

#### ì´ˆê¸°í™”
```python
def __init__(self, agent_name: str, checkpoint_dir: Optional[str] = None)
```

**íŒŒë¼ë¯¸í„°**:
- `agent_name` (str): ì—ì´ì „íŠ¸ ì´ë¦„
- `checkpoint_dir` (Optional[str]): ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë””ë ‰í† ë¦¬
  - ê¸°ë³¸ê°’: `checkpoints/{agent_name}`

**ìë™ ìƒì„± ì†ì„±**:
- `self.agent_name`: ì—ì´ì „íŠ¸ ì´ë¦„
- `self.logger`: `logging.getLogger(f"agent.{agent_name}")`
- `self.checkpoint_dir`: Path ê°ì²´ë¡œ ë³€í™˜ëœ ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬
- `self.checkpointer_path`: `{checkpoint_dir}/{agent_name}.db`
- `self.workflow`: StateGraph ì¸ìŠ¤í„´ìŠ¤ (Noneìœ¼ë¡œ ì‹œì‘)

**ì‹¤í–‰ ë¡œì§**:
1. ì²´í¬í¬ì¸íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„± (ë¼ì¸ 44)
2. `_build_graph()` í˜¸ì¶œí•˜ì—¬ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” (ë¼ì¸ 51)

---

### ì¶”ìƒ ë©”ì„œë“œ (ë°˜ë“œì‹œ êµ¬í˜„)

#### 1. `_get_state_schema() -> Type`
**ë¼ì¸**: 56-63
**ëª©ì **: ì—ì´ì „íŠ¸ê°€ ì‚¬ìš©í•  State TypedDict ë°˜í™˜

```python
@abstractmethod
def _get_state_schema(self) -> Type:
    """
    Get the state schema for this agent

    Returns:
        State schema type (TypedDict)
    """
    pass
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
def _get_state_schema(self) -> Type:
    return SalesState
```

---

#### 2. `_build_graph()`
**ë¼ì¸**: 65-71
**ëª©ì **: LangGraph StateGraph ìƒì„± ë° ë…¸ë“œ/ì—£ì§€ ì •ì˜

```python
@abstractmethod
def _build_graph(self):
    """
    Build the LangGraph workflow with context_schema
    Must call StateGraph with both state_schema and context_schema
    """
    pass
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
def _build_graph(self):
    from langgraph.graph import StateGraph
    from .context import AgentContext

    self.workflow = StateGraph(
        state_schema=self._get_state_schema(),
        context_schema=AgentContext
    )

    # ë…¸ë“œ ì¶”ê°€
    self.workflow.add_node("node1", self.node1_func)
    self.workflow.add_node("node2", self.node2_func)

    # ì—£ì§€ ì¶”ê°€
    self.workflow.add_edge("node1", "node2")
    self.workflow.set_entry_point("node1")
    self.workflow.set_finish_point("node2")
```

**ì¤‘ìš”**: ë°˜ë“œì‹œ `context_schema=AgentContext` ì§€ì • í•„ìš”

---

#### 3. `_validate_input(input_data: Dict[str, Any]) -> bool`
**ë¼ì¸**: 73-84
**ëª©ì **: ì‹¤í–‰ ì „ ì…ë ¥ ë°ì´í„° ê²€ì¦

```python
@abstractmethod
async def _validate_input(self, input_data: Dict[str, Any]) -> bool:
    """
    Validate input data before processing

    Args:
        input_data: Input data to validate

    Returns:
        True if valid, False otherwise
    """
    pass
```

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
async def _validate_input(self, input_data: Dict[str, Any]) -> bool:
    if "query" not in input_data:
        self.logger.error("Missing required field: query")
        return False

    if not isinstance(input_data["query"], str):
        self.logger.error("Query must be a string")
        return False

    return True
```

---

### ì£¼ìš” ë©”ì„œë“œ

#### `_create_initial_state(input_data: Dict[str, Any]) -> Dict[str, Any]`
**ë¼ì¸**: 86-103
**ëª©ì **: ì›Œí¬í”Œë¡œìš° ì´ˆê¸° ìƒíƒœ ìƒì„±

```python
def _create_initial_state(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Create initial state from input data
    Only includes workflow-specific fields (not context fields)

    Args:
        input_data: Input data from user

    Returns:
        Initial state dictionary with workflow fields only
    """
    return {
        "status": "pending",
        "execution_step": "starting",
        **{k: v for k, v in input_data.items()
           if k not in ["user_id", "session_id", "metadata",
                        "original_query", "intent_result"]}
    }
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- Context í•„ë“œ ì œì™¸ (`user_id`, `session_id`, `metadata` ë“±)
- ê¸°ë³¸ í•„ë“œ ì„¤ì •: `status: "pending"`, `execution_step: "starting"`
- ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ì—¬ ì»¤ìŠ¤í…€ í•„ë“œ ì¶”ê°€ ê°€ëŠ¥

---

#### `_create_context(input_data: Dict[str, Any]) -> AgentContext`
**ë¼ì¸**: 105-125
**ëª©ì **: ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸ ìƒì„±

```python
def _create_context(self, input_data: Dict[str, Any]) -> AgentContext:
    """
    Create context from input data
    Context contains metadata that doesn't change during execution

    Args:
        input_data: Input data containing context information

    Returns:
        AgentContext instance
    """
    return create_agent_context(
        user_id=input_data.get("user_id", "default"),
        session_id=input_data.get("session_id", "default"),
        context_type="agent",
        agent_name=self.agent_name,
        original_query=input_data.get("original_query", ""),
        intent_result=input_data.get("intent_result", {}),
        metadata=input_data.get("metadata", {}),
        request_id=input_data.get("request_id")
    )
```

**í•µì‹¬ í¬ì¸íŠ¸**:
- `user_id`, `session_id` í•„ìˆ˜ (ê¸°ë³¸ê°’: "default")
- `request_id` ë¯¸ì œê³µ ì‹œ ìë™ ìƒì„±
- ContextëŠ” ì‹¤í–‰ ì¤‘ READ-ONLY

---

#### `_wrap_node_with_runtime(node_func: Callable) -> Callable`
**ë¼ì¸**: 127-154
**ëª©ì **: ë…¸ë“œ í•¨ìˆ˜ì— Runtime íŒŒë¼ë¯¸í„° ìë™ ì£¼ì…

```python
def _wrap_node_with_runtime(self, node_func: Callable) -> Callable:
    """
    Wrap a node function to properly handle Runtime parameter
    This ensures nodes receive Runtime even if not explicitly passed

    Args:
        node_func: Original node function

    Returns:
        Wrapped function that handles Runtime
    """
    async def wrapped(state: Dict[str, Any],
                      runtime: Optional[Runtime] = None) -> Dict[str, Any]:
        import inspect
        sig = inspect.signature(node_func)

        if "runtime" in sig.parameters:
            if runtime is None:
                self.logger.warning(
                    f"Runtime not provided to {node_func.__name__}, using default"
                )
                return await node_func(state, runtime)
            return await node_func(state, runtime)
        else:
            self.logger.warning(
                f"Node {node_func.__name__} doesn't use Runtime - consider updating"
            )
            return await node_func(state)

    return wrapped
```

**ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤**:
- Runtime ë¯¸ì§€ì› ë ˆê±°ì‹œ ë…¸ë“œì™€ í˜¸í™˜ì„± ìœ ì§€
- Runtime íŒŒë¼ë¯¸í„° ìë™ ê²€ì‚¬ ë° ì£¼ì…

---

#### `execute(input_data: Dict[str, Any], config: Optional[Dict]) -> Dict[str, Any]`
**ë¼ì¸**: 156-260
**ëª©ì **: ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰

```python
async def execute(
    self,
    input_data: Dict[str, Any],
    config: Optional[Dict] = None
) -> Dict[str, Any]:
    """
    Execute the agent workflow with Context API

    Args:
        input_data: Input data for the agent
        config: Optional configuration for execution

    Returns:
        Dict containing execution results
    """
```

**ì‹¤í–‰ íë¦„**:

1. **ì…ë ¥ ê²€ì¦** (ë¼ì¸ 172-178)
   ```python
   if not await self._validate_input(input_data):
       return {
           "status": "error",
           "error": "Invalid input data",
           "agent": self.agent_name
       }
   ```

2. **ì´ˆê¸° ìƒíƒœ ìƒì„±** (ë¼ì¸ 181)
   ```python
   initial_state = self._create_initial_state(input_data)
   ```

3. **ì»¨í…ìŠ¤íŠ¸ ìƒì„±** (ë¼ì¸ 184)
   ```python
   context = self._create_context(input_data)
   ```

4. **Config ì¤€ë¹„** (ë¼ì¸ 187-195)
   ```python
   if config is None:
       config = {}

   config.setdefault("recursion_limit", 25)
   config.setdefault("configurable", {})
   config["configurable"]["thread_id"] = context.get("session_id", "default")
   ```

5. **ì›Œí¬í”Œë¡œìš° ì»´íŒŒì¼** (ë¼ì¸ 198-208)
   ```python
   if self.workflow is None:
       self.logger.error("Workflow not initialized")
       return {"status": "error", ...}

   async with AsyncSqliteSaver.from_conn_string(
       str(self.checkpointer_path)
   ) as checkpointer:
       app = self.workflow.compile(checkpointer=checkpointer)
   ```

6. **ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ ì ìš©)** (ë¼ì¸ 211-222)
   ```python
   timeout = config.get("timeout", 30)

   result = await asyncio.wait_for(
       app.ainvoke(
           initial_state,
           config=config,
           context=context
       ),
       timeout=timeout
   )
   ```

7. **ê²°ê³¼ ë°˜í™˜** (ë¼ì¸ 230-239)
   ```python
   return {
       "status": "success",
       "data": result,
       "agent": self.agent_name,
       "context": {
           "user_id": context.get("user_id", "unknown"),
           "session_id": context.get("session_id", "unknown"),
           "request_id": context.get("request_id", "unknown")
       }
   }
   ```

8. **íƒ€ì„ì•„ì›ƒ ì—ëŸ¬ ì²˜ë¦¬** (ë¼ì¸ 241-252)
   ```python
   except asyncio.TimeoutError:
       self.logger.error(f"Execution timed out after {timeout}s")
       return {
           "status": "error",
           "error": f"Execution timed out after {timeout} seconds",
           "agent": self.agent_name
       }
   ```

**ë°˜í™˜ í˜•ì‹**:
- **ì„±ê³µ ì‹œ**:
  ```python
  {
      "status": "success",
      "data": {...},  # ìµœì¢… ìƒíƒœ
      "agent": "agent_name",
      "context": {
          "user_id": "...",
          "session_id": "...",
          "request_id": "..."
      }
  }
  ```
- **ì‹¤íŒ¨ ì‹œ**:
  ```python
  {
      "status": "error",
      "error": "error message",
      "agent": "agent_name"
  }
  ```

---

#### `get_state(thread_id: str) -> Optional[Dict[str, Any]]`
**ë¼ì¸**: 262-280
**ëª©ì **: íŠ¹ì • ìŠ¤ë ˆë“œì˜ í˜„ì¬ ìƒíƒœ ì¡°íšŒ

```python
async def get_state(self, thread_id: str) -> Optional[Dict[str, Any]]:
    """
    Get the current state for a thread

    Args:
        thread_id: Thread ID to get state for

    Returns:
        Current state or None
    """
    try:
        async with AsyncSqliteSaver.from_conn_string(
            str(self.checkpointer_path)
        ) as checkpointer:
            app = self.workflow.compile(checkpointer=checkpointer)
            config = {"configurable": {"thread_id": thread_id}}
            state = await app.aget_state(config)
            return state.values if state else None
    except Exception as e:
        self.logger.error(f"Failed to get state: {e}")
        return None
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
current_state = await agent.get_state("session_123")
if current_state:
    print(f"Status: {current_state['status']}")
```

---

#### `update_state(thread_id: str, state_update: Dict, context: Optional[AgentContext]) -> bool`
**ë¼ì¸**: 282-311
**ëª©ì **: íŠ¹ì • ìŠ¤ë ˆë“œì˜ ìƒíƒœ ë¶€ë¶„ ì—…ë°ì´íŠ¸

```python
async def update_state(
    self,
    thread_id: str,
    state_update: Dict[str, Any],
    context: Optional[AgentContext] = None
) -> bool:
    """
    Update the state for a thread

    Args:
        thread_id: Thread ID to update
        state_update: State updates to apply (partial update)
        context: Optional context for the update

    Returns:
        True if successful, False otherwise
    """
    try:
        async with AsyncSqliteSaver.from_conn_string(
            str(self.checkpointer_path)
        ) as checkpointer:
            app = self.workflow.compile(checkpointer=checkpointer)
            config = {"configurable": {"thread_id": thread_id}}

            await app.aupdate_state(config, state_update)

            self.logger.info(
                f"State updated for thread {thread_id}: {list(state_update.keys())}"
            )
            return True
    except Exception as e:
        self.logger.error(f"Failed to update state: {e}")
        return False
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
success = await agent.update_state(
    "session_123",
    {"status": "processing", "execution_step": "data_collection"}
)
```

---

#### `create_partial_update(**kwargs) -> Dict[str, Any]`
**ë¼ì¸**: 314-325
**ëª©ì **: ë…¸ë“œì—ì„œ ìƒíƒœ ë¶€ë¶„ ì—…ë°ì´íŠ¸ ìƒì„±

```python
@staticmethod
def create_partial_update(**kwargs) -> Dict[str, Any]:
    """
    Helper to create partial state updates for nodes

    Usage in node:
        return self.create_partial_update(
            field1=new_value1,
            field2=new_value2
        )
    """
    return kwargs
```

**ì‚¬ìš© ì˜ˆì‹œ (ë…¸ë“œ ë‚´ë¶€)**:
```python
async def process_node(state: Dict, runtime: Runtime) -> Dict:
    # ì²˜ë¦¬ ë¡œì§
    result = do_something(state["query"])

    # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ë°˜í™˜
    return BaseAgent.create_partial_update(
        status="completed",
        result=result,
        execution_step="finished"
    )
```

---

### Context API í•µì‹¬ íŒ¨í„´

#### 1. Stateì™€ Context ë¶„ë¦¬
```python
# State: ì›Œí¬í”Œë¡œìš° ì¤‘ ë³€ê²½ë˜ëŠ” ë°ì´í„°
initial_state = {
    "status": "pending",
    "query": "Show me sales data",
    "sql_result": []
}

# Context: ì‹¤í–‰ ë‚´ë‚´ ë¶ˆë³€ì¸ ë©”íƒ€ë°ì´í„°
context = {
    "user_id": "user123",
    "session_id": "session456",
    "request_id": "req_abc123",
    "debug_mode": False
}
```

#### 2. ë…¸ë“œ ì‹œê·¸ë‹ˆì²˜
```python
async def my_node(state: Dict[str, Any], runtime: Runtime) -> Dict[str, Any]:
    # Context ì ‘ê·¼
    ctx = await runtime.context()
    user_id = ctx["user_id"]

    # State ì½ê¸° ë° ì—…ë°ì´íŠ¸
    query = state["query"]
    result = process_query(query)

    # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {"sql_result": [result], "status": "completed"}
```

#### 3. ainvoke í˜¸ì¶œ
```python
result = await app.ainvoke(
    initial_state,      # State (ë³€ê²½ ê°€ëŠ¥)
    config=config,      # ì‹¤í–‰ ì„¤ì •
    context=context     # Context (READ-ONLY)
)
```

---

## 3. checkpointer.py

### ê°œìš”
LangGraph ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ë¥¼ ìœ„í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

### í•¨ìˆ˜: `get_checkpointer`
**ë¼ì¸**: 15-47

```python
def get_checkpointer(
    checkpoint_path: str,
    async_mode: bool = True
) -> Optional[AsyncSqliteSaver]:
    """
    Get a checkpointer instance

    Args:
        checkpoint_path: Path to the checkpoint database
        async_mode: Whether to use async checkpointer

    Returns:
        Checkpointer instance or None if failed
    """
    try:
        checkpoint_path = Path(checkpoint_path)
        checkpoint_path.parent.mkdir(parents=True, exist_ok=True)

        if async_mode:
            checkpointer = AsyncSqliteSaver.from_conn_string(
                str(checkpoint_path)
            )
            logger.info(f"AsyncSqliteSaver initialized at {checkpoint_path}")
        else:
            checkpointer = SqliteSaver.from_conn_string(str(checkpoint_path))
            logger.info(f"SqliteSaver initialized at {checkpoint_path}")

        return checkpointer

    except Exception as e:
        logger.error(f"Failed to initialize checkpointer: {e}")
        return None
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
checkpointer = get_checkpointer("checkpoints/sales_agent/session_123.db")
if checkpointer:
    app = workflow.compile(checkpointer=checkpointer)
```

**ì£¼ì˜ì‚¬í•­**:
- í˜„ì¬ `__init__.py`ì—ì„œ ë¹„í™œì„±í™”ë¨ (ë¼ì¸ 24, 46)
- BaseAgentëŠ” ì§ì ‘ AsyncSqliteSaverë¥¼ ì‚¬ìš© (base_agent.py ë¼ì¸ 207)

---

### í•¨ìˆ˜: `cleanup_old_checkpoints`
**ë¼ì¸**: 50-94

```python
async def cleanup_old_checkpoints(
    checkpoint_dir: Path,
    keep_last: int = 5
) -> int:
    """
    Clean up old checkpoint files

    Args:
        checkpoint_dir: Directory containing checkpoints
        keep_last: Number of recent checkpoints to keep

    Returns:
        Number of files cleaned up
    """
    try:
        if not checkpoint_dir.exists():
            return 0

        # ìˆ˜ì • ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        checkpoint_files = sorted(
            checkpoint_dir.glob("*.db"),
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )

        # ìµœì‹  íŒŒì¼ë§Œ ìœ ì§€
        files_to_remove = checkpoint_files[keep_last:]
        removed_count = 0

        for file_path in files_to_remove:
            try:
                file_path.unlink()
                removed_count += 1
                logger.debug(f"Removed old checkpoint: {file_path}")
            except Exception as e:
                logger.error(f"Failed to remove {file_path}: {e}")

        if removed_count > 0:
            logger.info(f"Cleaned up {removed_count} old checkpoint files")

        return removed_count

    except Exception as e:
        logger.error(f"Failed to cleanup checkpoints: {e}")
        return 0
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from pathlib import Path

checkpoint_dir = Path("checkpoints/sales_agent")
removed = await cleanup_old_checkpoints(checkpoint_dir, keep_last=10)
print(f"Removed {removed} old checkpoints")
```

---

## 4. config.py

### ê°œìš”
ì‹œìŠ¤í…œ ì „ì—­ ì •ì  ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤ì…ë‹ˆë‹¤.

---

### í´ë˜ìŠ¤: `Config`

#### ê²½ë¡œ ì„¤ì •
**ë¼ì¸**: 22-30

```python
BASE_DIR = Path(__file__).parent.parent.parent.parent  # í”„ë¡œì íŠ¸ ë£¨íŠ¸
DB_DIR = BASE_DIR / "database" / "storage"
CHECKPOINT_DIR = BASE_DIR / "checkpoints"
LOG_DIR = BASE_DIR / "logs"

# ë””ë ‰í† ë¦¬ ìë™ ìƒì„±
for directory in [CHECKPOINT_DIR, LOG_DIR]:
    directory.mkdir(parents=True, exist_ok=True)
```

**ê²½ë¡œ êµ¬ì¡°**:
```
beta_v003/                      (BASE_DIR)
â”œâ”€â”€ database/
â”‚   â””â”€â”€ storage/                (DB_DIR)
â”œâ”€â”€ checkpoints/                (CHECKPOINT_DIR)
â””â”€â”€ logs/                       (LOG_DIR)
```

---

#### ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
**ë¼ì¸**: 32-39

```python
DATABASES = {
    "hr_info": DB_DIR / "hr_information" / "hr_data.db",
    "hr_rules": DB_DIR / "hr_rules" / "chromadb",
    "sales_performance": DB_DIR / "sales_performance" / "sales_performance_db.db",
    "sales_targets": DB_DIR / "sales_performance" / "sales_target_db.db",
    "clients": DB_DIR / "sales_performance" / "clients_db.db",
}
```

**ë°ì´í„°ë² ì´ìŠ¤ ëª©ë¡**:
| í‚¤ | ê²½ë¡œ | ìš©ë„ |
|---|---|---|
| `hr_info` | `hr_information/hr_data.db` | ì¸ì‚¬ ì •ë³´ |
| `hr_rules` | `hr_rules/chromadb` | ì¸ì‚¬ ê·œì • (Vector DB) |
| `sales_performance` | `sales_performance/sales_performance_db.db` | ì˜ì—… ì‹¤ì  |
| `sales_targets` | `sales_performance/sales_target_db.db` | ì˜ì—… ëª©í‘œ |
| `clients` | `sales_performance/clients_db.db` | ê³ ê° ì •ë³´ |

---

#### ëª¨ë¸ ì„¤ì •
**ë¼ì¸**: 41-50

```python
DEFAULT_MODELS = {
    "intent": "gpt-4o-mini",      # ë¹ ë¥¸ ì¸í…íŠ¸ ë¶„ì„
    "planning": "gpt-4o",          # ì •í™•í•œ ê³„íš ìˆ˜ë¦½
}

DEFAULT_MODEL_PARAMS = {
    "intent": {"temperature": 0.3, "max_tokens": 500},
    "planning": {"temperature": 0.3, "max_tokens": 2000},
}
```

**ëª¨ë¸ ìš©ë„**:
- **intent**: ì‚¬ìš©ì ì˜ë„ ë¶„ë¥˜ (ë¹ ë¥¸ ì‘ë‹µ í•„ìš”)
- **planning**: ì‹¤í–‰ ê³„íš ìˆ˜ë¦½ (ì •í™•ë„ ìš°ì„ )

---

#### íƒ€ì„ì•„ì›ƒ ì„¤ì •
**ë¼ì¸**: 52-56

```python
TIMEOUTS = {
    "agent": 30,           # ê°œë³„ ì—ì´ì „íŠ¸ íƒ€ì„ì•„ì›ƒ (ì´ˆ)
    "llm": 20,             # LLM í˜¸ì¶œ íƒ€ì„ì•„ì›ƒ
}
```

---

#### ì‹œìŠ¤í…œ ì œí•œ
**ë¼ì¸**: 58-64

```python
LIMITS = {
    "max_recursion": 25,           # ìµœëŒ€ ì¬ê·€ ê¹Šì´
    "max_retries": 3,              # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    "max_message_length": 10000,   # ë©”ì‹œì§€ ìµœëŒ€ ê¸¸ì´
    "max_sql_results": 1000,       # SQL ê²°ê³¼ ìµœëŒ€ í–‰ ìˆ˜
}
```

---

#### ì‹¤í–‰ ì„¤ì •
**ë¼ì¸**: 66-69

```python
EXECUTION = {
    "enable_checkpointing": True,  # ì²´í¬í¬ì¸íŒ… í™œì„±í™”
}
```

---

#### ë¡œê¹… ì„¤ì •
**ë¼ì¸**: 71-79

```python
LOGGING = {
    "level": os.getenv("LOG_LEVEL", "INFO"),
    "format": "%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    "date_format": "%Y-%m-%d %H:%M:%S",
    "file_rotation": "daily",      # ì¼ì¼ ë¡œí…Œì´ì…˜
    "max_log_size": "100MB",       # ìµœëŒ€ ë¡œê·¸ íŒŒì¼ í¬ê¸°
    "backup_count": 7              # ë°±ì—… íŒŒì¼ ìˆ˜
}
```

---

#### ê¸°ëŠ¥ í”Œë˜ê·¸
**ë¼ì¸**: 81-84

```python
FEATURES = {
    "enable_llm_planning": True,  # LLM ê¸°ë°˜ ê³„íš ìˆ˜ë¦½ í™œì„±í™”
}
```

---

### í—¬í¼ ë©”ì„œë“œ

#### `get_database_path(db_name: str) -> Path`
**ë¼ì¸**: 88-91

```python
@classmethod
def get_database_path(cls, db_name: str) -> Path:
    """Get database path by name"""
    return cls.DATABASES.get(db_name, cls.DB_DIR / f"{db_name}.db")
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
sales_db = Config.get_database_path("sales_performance")
# ë°˜í™˜: Path("database/storage/sales_performance/sales_performance_db.db")
```

---

#### `get_checkpoint_path(agent_name: str, session_id: str) -> Path`
**ë¼ì¸**: 93-98

```python
@classmethod
def get_checkpoint_path(cls, agent_name: str, session_id: str) -> Path:
    """Get checkpoint database path for an agent session"""
    checkpoint_dir = cls.CHECKPOINT_DIR / agent_name
    checkpoint_dir.mkdir(parents=True, exist_ok=True)
    return checkpoint_dir / f"{session_id}.db"
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
checkpoint_path = Config.get_checkpoint_path("sales_agent", "session_123")
# ë°˜í™˜: Path("checkpoints/sales_agent/session_123.db")
```

---

#### `get_model_config(model_type: str) -> Dict[str, Any]`
**ë¼ì¸**: 100-106

```python
@classmethod
def get_model_config(cls, model_type: str) -> Dict[str, Any]:
    """Get model configuration by type"""
    return {
        "model": cls.DEFAULT_MODELS.get(model_type, "gpt-4o-mini"),
        **cls.DEFAULT_MODEL_PARAMS.get(model_type, {})
    }
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
config = Config.get_model_config("planning")
# ë°˜í™˜: {"model": "gpt-4o", "temperature": 0.3, "max_tokens": 2000}
```

---

#### `validate() -> bool`
**ë¼ì¸**: 108-129

```python
@classmethod
def validate(cls) -> bool:
    """Validate configuration"""
    issues = []

    # ë°ì´í„°ë² ì´ìŠ¤ ë””ë ‰í† ë¦¬ í™•ì¸
    for name, path in cls.DATABASES.items():
        if not path.parent.exists():
            issues.append(f"Database directory missing: {path.parent}")

    # í•„ìˆ˜ ë””ë ‰í† ë¦¬ í™•ì¸
    for directory in [cls.CHECKPOINT_DIR, cls.LOG_DIR]:
        if not directory.exists():
            issues.append(f"Required directory missing: {directory}")

    if issues:
        print("Configuration issues found:")
        for issue in issues:
            print(f"  - {issue}")
        return False

    return True
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
if not Config.validate():
    print("Configuration validation failed!")
    sys.exit(1)
```

---

#### `to_dict() -> Dict[str, Any]`
**ë¼ì¸**: 131-140

```python
@classmethod
def to_dict(cls) -> Dict[str, Any]:
    """Export configuration as dictionary"""
    return {
        "databases": {k: str(v) for k, v in cls.DATABASES.items()},
        "models": cls.DEFAULT_MODELS,
        "timeouts": cls.TIMEOUTS,
        "limits": cls.LIMITS,
        "features": cls.FEATURES
    }
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
import json

config_dict = Config.to_dict()
print(json.dumps(config_dict, indent=2))
```

---

## 5. context.py

### ê°œìš”
LangGraph 0.6.x Context APIë¥¼ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ì •ì˜ ë° í—¬í¼ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

### TypedDict: `AgentContext`
**ë¼ì¸**: 15-45

```python
class AgentContext(TypedDict):
    """
    Runtime context for agents
    Contains metadata and configuration passed at execution time
    This is READ-ONLY during execution
    """
```

#### í•„ë“œ êµ¬ì„±

**í•„ìˆ˜ í•„ë“œ**:
```python
user_id: str                # ì‚¬ìš©ì ì‹ë³„ì
session_id: str             # ì„¸ì…˜ ì‹ë³„ì
```

**ëŸ°íƒ€ì„ ì •ë³´ (ì„ íƒ)**:
```python
request_id: Optional[str]       # ìš”ì²­ ê³ ìœ  ID
timestamp: Optional[str]        # ìš”ì²­ íƒ€ì„ìŠ¤íƒ¬í”„ (ISO 8601)
original_query: Optional[str]   # ì›ë³¸ ì‚¬ìš©ì ì…ë ¥
```

**ì¸ì¦ (ì„ íƒ)**:
```python
api_keys: Optional[Dict[str, str]]  # ì„œë¹„ìŠ¤ API í‚¤
```

**ì‚¬ìš©ì ì„¤ì • (ì„ íƒ)**:
```python
language: Optional[str]     # ì‚¬ìš©ì ì–¸ì–´ (ko, en, ë“±)
```

**ëŸ°íƒ€ì„ ì„¤ì • (ì„ íƒ)**:
```python
timeout_overrides: Optional[Dict[str, int]]  # íƒ€ì„ì•„ì›ƒ ì˜¤ë²„ë¼ì´ë“œ
```

**ì‹¤í–‰ ì œì–´ (ì„ íƒ)**:
```python
debug_mode: Optional[bool]      # ë””ë²„ê·¸ ë¡œê¹… í™œì„±í™”
dry_run: Optional[bool]         # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
strict_mode: Optional[bool]     # ì—„ê²©í•œ ì—ëŸ¬ ì²˜ë¦¬
max_retries: Optional[int]      # ì¬ì‹œë„ íšŸìˆ˜ ì˜¤ë²„ë¼ì´ë“œ
```

---

### TypedDict: `SubgraphContext`
**ë¼ì¸**: 47-70

```python
class SubgraphContext(TypedDict):
    """
    Context for subgraphs (filtered subset of AgentContext)
    Used when invoking DataCollectionSubgraph, AnalysisSubgraph, etc.
    """
```

#### í•„ë“œ êµ¬ì„±

**ë¶€ëª¨ë¡œë¶€í„° ìƒì† (í•„ìˆ˜)**:
```python
user_id: str
session_id: str
```

**ë¶€ëª¨ë¡œë¶€í„° ìƒì† (ì„ íƒ)**:
```python
request_id: Optional[str]
language: Optional[str]
debug_mode: Optional[bool]
```

**ì„œë¸Œê·¸ë˜í”„ ì‹ë³„**:
```python
parent_agent: str           # ë¶€ëª¨ ì—ì´ì „íŠ¸ ì´ë¦„
subgraph_name: str         # í˜„ì¬ ì„œë¸Œê·¸ë˜í”„ ì´ë¦„
```

**ì„œë¸Œê·¸ë˜í”„ íŒŒë¼ë¯¸í„°**:
```python
suggested_tools: Optional[List[str]]    # ë„êµ¬ íŒíŠ¸
analysis_depth: Optional[str]           # shallow, normal, deep
db_paths: Optional[Dict[str, str]]     # ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ
```

---

### í•¨ìˆ˜: `create_agent_context`
**ë¼ì¸**: 74-111

```python
def create_agent_context(
    user_id: str,
    session_id: str,
    **kwargs
) -> Dict[str, Any]:
    """
    Create AgentContext with required fields and optional values

    Args:
        user_id: User identifier
        session_id: Session identifier
        **kwargs: Optional context fields

    Returns:
        Context dictionary ready for LangGraph
    """
```

**ìë™ ìƒì„± í•„ë“œ**:
- `request_id`: ë¯¸ì œê³µ ì‹œ `f"req_{uuid.uuid4().hex[:8]}"` ìƒì„±
- `timestamp`: ë¯¸ì œê³µ ì‹œ `datetime.now().isoformat()` ìƒì„±

**ê¸°ë³¸ê°’**:
- `language`: "ko"
- `debug_mode`: False
- `strict_mode`: True

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
context = create_agent_context(
    user_id="user123",
    session_id="session456",
    original_query="Show me sales data",
    debug_mode=True,
    api_keys={"openai_api_key": "sk-..."}
)
```

**ë°˜í™˜ ì˜ˆì‹œ**:
```python
{
    "user_id": "user123",
    "session_id": "session456",
    "request_id": "req_a1b2c3d4",
    "timestamp": "2025-09-27T10:30:00.123456",
    "original_query": "Show me sales data",
    "api_keys": {"openai_api_key": "sk-..."},
    "language": "ko",
    "debug_mode": True,
    "strict_mode": True
}
```

---

### í•¨ìˆ˜: `merge_with_config_defaults`
**ë¼ì¸**: 114-140

```python
def merge_with_config_defaults(
    context: Dict[str, Any],
    config: Any
) -> Dict[str, Any]:
    """
    Merge context with config defaults
    Context values take precedence

    Args:
        context: Runtime context
        config: Config instance

    Returns:
        Merged context with defaults
    """
```

**ë™ì‘**:
1. Contextì— `timeout_overrides`ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë”•ì…”ë„ˆë¦¬ ìƒì„±
2. Configì—ì„œ `agent`, `llm` íƒ€ì„ì•„ì›ƒ ê°€ì ¸ì™€ ì¶”ê°€ (ê¸°ë³¸ 30ì´ˆ)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
from .config import Config

context = create_agent_context("user123", "session456")
context = merge_with_config_defaults(context, Config)

# context["timeout_overrides"] ì¶”ê°€ë¨:
# {"agent": 30, "llm": 20}
```

---

### í•¨ìˆ˜: `create_subgraph_context`
**ë¼ì¸**: 143-182

```python
def create_subgraph_context(
    parent_context: Dict[str, Any],
    parent_agent: str,
    subgraph_name: str,
    **kwargs
) -> Dict[str, Any]:
    """
    Create context for subgraphs (filtered subset of parent context)

    Args:
        parent_context: Parent agent's context
        parent_agent: Parent agent name
        subgraph_name: Subgraph name
        **kwargs: Additional subgraph-specific parameters

    Returns:
        Filtered context for subgraph
    """
```

**í•„í„°ë§ ê·œì¹™**:
- ë¶€ëª¨ Contextì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ (`user_id`, `session_id`, `request_id`, `language`, `debug_mode`)
- ì„œë¸Œê·¸ë˜í”„ ì‹ë³„ ì •ë³´ ì¶”ê°€
- ì„œë¸Œê·¸ë˜í”„ë³„ íŒŒë¼ë¯¸í„° ì¶”ê°€ (`suggested_tools`, `analysis_depth`, `db_paths`)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
parent_ctx = create_agent_context("user123", "session456", debug_mode=True)

subgraph_ctx = create_subgraph_context(
    parent_context=parent_ctx,
    parent_agent="sales_agent",
    subgraph_name="data_collection",
    suggested_tools=["sql_query", "aggregate"],
    analysis_depth="deep",
    db_paths={
        "sales_performance": "database/storage/sales_performance/sales_performance_db.db"
    }
)
```

**ë°˜í™˜ ì˜ˆì‹œ**:
```python
{
    "user_id": "user123",
    "session_id": "session456",
    "request_id": "req_a1b2c3d4",
    "language": "ko",
    "debug_mode": True,
    "parent_agent": "sales_agent",
    "subgraph_name": "data_collection",
    "suggested_tools": ["sql_query", "aggregate"],
    "analysis_depth": "deep",
    "db_paths": {
        "sales_performance": "..."
    }
}
```

---

### í•¨ìˆ˜: `extract_api_keys_from_env`
**ë¼ì¸**: 185-206

```python
def extract_api_keys_from_env() -> Dict[str, str]:
    """
    Extract API keys from environment variables

    Returns:
        Dictionary of API keys
    """
```

**ì§€ì› í‚¤**:
- `OPENAI_API_KEY`
- `ANTHROPIC_API_KEY`

**ë™ì‘**:
1. í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ íŒ¨í„´ ê²€ìƒ‰
2. í‚¤ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜ (`openai_api_key`)

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
api_keys = extract_api_keys_from_env()
# ë°˜í™˜: {"openai_api_key": "sk-...", "anthropic_api_key": "..."}

context = create_agent_context(
    user_id="user123",
    session_id="session456",
    api_keys=api_keys
)
```

---

## 6. states.py

### ê°œìš”
LangGraph ì›Œí¬í”Œë¡œìš°ì—ì„œ ì‚¬ìš©í•˜ëŠ” State ì •ì˜ ë° ë¦¬ë“€ì„œ í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

---

### ë¦¬ë“€ì„œ í•¨ìˆ˜

#### `merge_dicts(a: Dict, b: Dict) -> Dict`
**ë¼ì¸**: 14-20

```python
def merge_dicts(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    """Merge dictionaries, b overwrites a"""
    if not a:
        return b or {}
    if not b:
        return a
    return {**a, **b}
```

**ì‚¬ìš©**:
```python
aggregated_data: Annotated[Dict[str, Any], merge_dicts]
```

**ë™ì‘**:
```python
a = {"x": 1, "y": 2}
b = {"y": 3, "z": 4}
result = merge_dicts(a, b)
# ê²°ê³¼: {"x": 1, "y": 3, "z": 4}
```

---

#### `append_unique(a: List, b: List) -> List`
**ë¼ì¸**: 23-33

```python
def append_unique(a: List[Any], b: List[Any]) -> List[Any]:
    """Append only unique items to list"""
    if not a:
        a = []
    if not b:
        return a
    result = a.copy()
    for item in b:
        if item not in result:
            result.append(item)
    return result
```

**ì‚¬ìš©**:
```python
insights: Annotated[List[str], append_unique]
```

**ë™ì‘**:
```python
a = ["insight1", "insight2"]
b = ["insight2", "insight3"]
result = append_unique(a, b)
# ê²°ê³¼: ["insight1", "insight2", "insight3"]
```

---

### TypedDict: `BaseState`
**ë¼ì¸**: 38-51

```python
class BaseState(TypedDict):
    """Base state for all workflows"""
```

**í•„ë“œ**:
```python
# ìƒíƒœ ì¶”ì  (ë®ì–´ì“°ê¸°)
status: str                # pending, processing, completed, failed
execution_step: str        # í˜„ì¬ ì›Œí¬í”Œë¡œìš° ë‹¨ê³„

# ì—ëŸ¬ ì¶”ì  (ëˆ„ì )
errors: Annotated[List[str], add]  # ì—ëŸ¬ ë©”ì‹œì§€

# íƒ€ì´ë° (ë®ì–´ì“°ê¸°)
start_time: Optional[str]
end_time: Optional[str]
```

**ëª¨ë“  Stateì˜ ê¸°ë³¸ í•„ë“œ**

---

### TypedDict: `DataCollectionState`
**ë¼ì¸**: 55-74

```python
class DataCollectionState(TypedDict):
    """State for data collection subgraph"""
```

**ì…ë ¥**:
```python
query_params: Dict[str, Any]    # ë°ì´í„° ìˆ˜ì§‘ íŒŒë¼ë¯¸í„°
target_databases: List[str]     # ì¿¼ë¦¬í•  ë°ì´í„°ë² ì´ìŠ¤
```

**ìˆ˜ì§‘ ê²°ê³¼ (ëˆ„ì )**:
```python
performance_data: Annotated[List[Dict[str, Any]], add]
target_data: Annotated[List[Dict[str, Any]], add]
client_data: Annotated[List[Dict[str, Any]], add]
```

**ì§‘ê³„ ë°ì´í„° (ë³‘í•©)**:
```python
aggregated_performance: Annotated[Dict[str, Any], merge_dicts]
aggregated_target: Annotated[Dict[str, Any], merge_dicts]
aggregated_client: Annotated[Dict[str, Any], merge_dicts]
```

**ìƒíƒœ**:
```python
collection_status: str
errors: Annotated[List[str], add]
```

---

### TypedDict: `AnalysisState`
**ë¼ì¸**: 76-99

```python
class AnalysisState(TypedDict):
    """State for analysis subgraph"""
```

**ì…ë ¥ ë°ì´í„° (ë°ì´í„° ìˆ˜ì§‘ì—ì„œ)**:
```python
performance_data: List[Dict[str, Any]]
target_data: List[Dict[str, Any]]
client_data: List[Dict[str, Any]]
```

**ë¶„ì„ íŒŒë¼ë¯¸í„°**:
```python
analysis_type: str          # basic, trend, comparative, comprehensive
analysis_params: Dict[str, Any]
```

**ë¶„ì„ ê²°ê³¼ (ë³‘í•©)**:
```python
basic_metrics: Annotated[Dict[str, Any], merge_dicts]
trend_analysis: Annotated[Dict[str, Any], merge_dicts]
comparative_analysis: Annotated[Dict[str, Any], merge_dicts]
insights: Annotated[List[str], append_unique]
```

**ìµœì¢… ë³´ê³ ì„œ**:
```python
analysis_report: Optional[Dict[str, Any]]
```

**ìƒíƒœ**:
```python
analysis_status: str
errors: Annotated[List[str], add]
```

---

### TypedDict: `SalesState` (BaseState ìƒì†)
**ë¼ì¸**: 103-142

```python
class SalesState(BaseState):
    """
    Sales Analytics Agent State
    Workflow data that changes during execution
    """
```

#### í•„ë“œ êµ¬ì„±

**ì…ë ¥ (ë®ì–´ì“°ê¸°)**:
```python
query: str                      # ì‚¬ìš©ì ì¿¼ë¦¬
employee_name: Optional[str]    # ì§ì› ì´ë¦„
period: Optional[str]           # daily, weekly, monthly, yearly
metrics_type: Optional[str]     # performance, revenue, targets
```

**ê³„íš (ë®ì–´ì“°ê¸°)**:
```python
execution_plan: Optional[Dict[str, Any]]  # LLM ìƒì„± ì‹¤í–‰ ê³„íš
```

**ì¿¼ë¦¬ ì²˜ë¦¬ (ë®ì–´ì“°ê¸°)**:
```python
parsed_query: Dict[str, Any]    # íŒŒì‹±ëœ ì¿¼ë¦¬ êµ¬ì„± ìš”ì†Œ
generated_sql: Optional[str]    # ìƒì„±ëœ SQL ì¿¼ë¦¬
```

**ë°ì´í„° ìˆ˜ì§‘ (ëˆ„ì )**:
```python
sql_result: Annotated[List[Dict[str, Any]], add]  # SQL ì¿¼ë¦¬ ê²°ê³¼
```

**ì„œë¸Œê·¸ë˜í”„ ê²°ê³¼ (ë®ì–´ì“°ê¸°)**:
```python
data_collection_result: Optional[Dict[str, Any]]  # DataCollectionSubgraph ê²°ê³¼
analysis_result: Optional[Dict[str, Any]]         # AnalysisSubgraph ê²°ê³¼
```

**ì§‘ê³„ (ë³‘í•©)**:
```python
collected_data: Annotated[Dict[str, Any], merge_dicts]      # ì„œë¸Œê·¸ë˜í”„ ë°ì´í„°
execution_results: Annotated[Dict[str, Any], merge_dicts]   # ì‹¤í–‰ ê²°ê³¼
aggregated_data: Annotated[Dict[str, Any], merge_dicts]     # ì§‘ê³„ ë©”íŠ¸ë¦­
statistics: Annotated[Dict[str, float], merge_dicts]        # í†µê³„ ìš”ì•½
```

**ë¶„ì„ (ì¤‘ë³µ ì œê±° ëˆ„ì )**:
```python
insights: Annotated[List[str], append_unique]           # ê³ ìœ  ì¸ì‚¬ì´íŠ¸
recommendations: Annotated[List[str], append_unique]    # ì•¡ì…˜ ì¶”ì²œ
```

**ì¶œë ¥ (ë®ì–´ì“°ê¸°)**:
```python
formatted_result: Optional[str]         # ì‚¬ëŒì´ ì½ì„ ìˆ˜ ìˆëŠ” ê²°ê³¼
final_report: Optional[Dict[str, Any]]  # ì™„ì „í•œ ë³´ê³ ì„œ
```

---

### TypedDict: `DocumentState` (BaseState ìƒì†)
**ë¼ì¸**: 144-172

```python
class DocumentState(BaseState):
    """
    State for document generation workflows
    """
```

#### í•„ë“œ êµ¬ì„±

**ë¬¸ì„œ ê´€ë ¨ í•„ë“œ**:
```python
doc_type: str               # sales_report, product_seminar_application ë“±
doc_format: str             # markdown, html, text, word
title: str                  # ë¬¸ì„œ ì œëª©
input_data: Dict[str, Any]  # ì…ë ¥ ë°ì´í„°
template_id: str            # í…œí”Œë¦¿ ì‹ë³„ì
sections: List[Dict[str, Any]]  # ë¬¸ì„œ ì„¹ì…˜
content: str                # ì›ì‹œ ì½˜í…ì¸ 
formatted_content: str      # í¬ë§·ëœ ì½˜í…ì¸ 
document_metadata: Dict[str, Any]  # ë¬¸ì„œ ë©”íƒ€ë°ì´í„°
final_document: Dict[str, Any]     # ìµœì¢… ë¬¸ì„œ
```

**ì¸í„°ë™í‹°ë¸Œ ì²˜ë¦¬ í•„ë“œ**:
```python
user_query: Optional[str]                   # ì›ë³¸ ì‚¬ìš©ì ì¿¼ë¦¬
query_analysis: Optional[Dict[str, Any]]    # LLM ë¶„ì„ ê²°ê³¼
template_analysis: Optional[Dict[str, Any]] # í…œí”Œë¦¿ í•„ë“œ ë¶„ì„
required_fields: Optional[List[Dict[str, Any]]]  # í•„ìˆ˜ í•„ë“œ ì •ì˜
missing_fields: Optional[List[Dict[str, Any]]]   # ëˆ„ë½ëœ í•„ë“œ
collected_data: Annotated[Dict[str, Any], merge_dicts]  # ì¸í„°ë™í‹°ë¸Œ ìˆ˜ì§‘ ë°ì´í„°
interaction_mode: Optional[str]             # interactive, batch, auto
interaction_history: Annotated[List[Dict[str, Any]], add]  # ì¸í„°ë™ì…˜ íˆìŠ¤í† ë¦¬
needs_user_input: bool                      # ì‚¬ìš©ì ì…ë ¥ í•„ìš” í”Œë˜ê·¸
current_prompt: Optional[str]               # í˜„ì¬ í”„ë¡¬í”„íŠ¸
user_response: Optional[str]                # ìµœì‹  ì‚¬ìš©ì ì‘ë‹µ
```

---

### í•¨ìˆ˜: `create_sales_initial_state`
**ë¼ì¸**: 176-227

```python
def create_sales_initial_state(**kwargs) -> Dict[str, Any]:
    """
    Create initial SalesState with defaults

    Args:
        **kwargs: Initial field values

    Returns:
        Initial state dictionary
    """
```

**ê¸°ë³¸ê°’**:
```python
{
    # ìƒíƒœ
    "status": "pending",
    "execution_step": "initializing",
    "errors": [],
    "start_time": datetime.now().isoformat(),

    # ì…ë ¥
    "query": kwargs.get("query", ""),
    "employee_name": kwargs.get("employee_name"),
    "period": kwargs.get("period", "monthly"),
    "metrics_type": kwargs.get("metrics_type", "performance"),

    # ê³„íš
    "execution_plan": None,

    # ì¿¼ë¦¬ ì²˜ë¦¬
    "parsed_query": {},
    "generated_sql": None,

    # ë°ì´í„° ìˆ˜ì§‘
    "sql_result": [],

    # ì„œë¸Œê·¸ë˜í”„ ê²°ê³¼
    "data_collection_result": None,
    "analysis_result": None,

    # ì§‘ê³„
    "collected_data": {},
    "execution_results": {},
    "aggregated_data": {},
    "statistics": {},

    # ë¶„ì„
    "insights": [],
    "recommendations": [],

    # ì¶œë ¥
    "formatted_result": None,
    "final_report": None,
    "end_time": None
}
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
initial_state = create_sales_initial_state(
    query="Show me monthly sales for John",
    employee_name="John",
    period="monthly"
)
```

---

### í•¨ìˆ˜: `merge_state_updates`
**ë¼ì¸**: 230-245

```python
def merge_state_updates(*updates: Dict[str, Any]) -> Dict[str, Any]:
    """
    Merge multiple state updates

    Args:
        *updates: State update dictionaries

    Returns:
        Merged state update
    """
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
update1 = {"status": "processing", "execution_step": "data_collection"}
update2 = {"sql_result": [{"row": 1}]}
update3 = {"insights": ["High performance"]}

merged = merge_state_updates(update1, update2, update3)
# ê²°ê³¼: {"status": "processing", "execution_step": "data_collection",
#        "sql_result": [{"row": 1}], "insights": ["High performance"]}
```

---

### í•¨ìˆ˜: `get_state_summary`
**ë¼ì¸**: 248-267

```python
def get_state_summary(state: Dict[str, Any]) -> Dict[str, Any]:
    """
    Get summary of current state

    Args:
        state: Current state

    Returns:
        Summary dictionary
    """
```

**ë°˜í™˜ ì˜ˆì‹œ**:
```python
{
    "status": "completed",
    "step": "formatting_results",
    "errors_count": 0,
    "has_results": True,
    "data_collected": True,
    "insights_count": 5,
    "start_time": "2025-09-27T10:00:00",
    "end_time": "2025-09-27T10:00:30"
}
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
summary = get_state_summary(current_state)
print(f"Status: {summary['status']}, Step: {summary['step']}")
```

---

## í•µì‹¬ ê°œë…

### 1. State vs Context

| í•­ëª© | State | Context |
|------|-------|---------|
| **ì •ì˜** | ì›Œí¬í”Œë¡œìš° ì¤‘ ë³€ê²½ë˜ëŠ” ë°ì´í„° | ì‹¤í–‰ ë‚´ë‚´ ë¶ˆë³€ì¸ ë©”íƒ€ë°ì´í„° |
| **ë³€ê²½ ê°€ëŠ¥** | âœ… ë…¸ë“œì—ì„œ ìˆ˜ì • ê°€ëŠ¥ | âŒ READ-ONLY |
| **ì „ë‹¬ ë°©ì‹** | `ainvoke(state, ...)` | `ainvoke(..., context=ctx)` |
| **ì˜ˆì‹œ** | `sql_result`, `insights`, `status` | `user_id`, `session_id`, `request_id` |
| **ìš©ë„** | ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒí™© ì¶”ì  | ì‚¬ìš©ì/ì„¸ì…˜ ì‹ë³„, ì„¤ì • ì „ë‹¬ |

**ì½”ë“œ ì˜ˆì‹œ**:
```python
# State: ì›Œí¬í”Œë¡œìš° ë°ì´í„°
state = {
    "status": "pending",
    "query": "Show me sales",
    "sql_result": [],
    "insights": []
}

# Context: ë©”íƒ€ë°ì´í„°
context = {
    "user_id": "user123",
    "session_id": "session456",
    "request_id": "req_abc",
    "debug_mode": False
}

# ì‹¤í–‰
result = await app.ainvoke(state, config=config, context=context)
```

---

### 2. Reducer íŒ¨í„´

LangGraphëŠ” `Annotated[Type, reducer]`ë¥¼ ì‚¬ìš©í•˜ì—¬ State í•„ë“œ ì—…ë°ì´íŠ¸ ë°©ì‹ì„ ì •ì˜í•©ë‹ˆë‹¤.

#### ë‚´ì¥ Reducer: `add`
```python
from operator import add

errors: Annotated[List[str], add]
```

**ë™ì‘**:
```python
# ë…¸ë“œ 1
return {"errors": ["Error A"]}

# ë…¸ë“œ 2
return {"errors": ["Error B"]}

# ìµœì¢… state["errors"] = ["Error A", "Error B"]
```

---

#### ì»¤ìŠ¤í…€ Reducer: `merge_dicts`
```python
aggregated_data: Annotated[Dict[str, Any], merge_dicts]
```

**ë™ì‘**:
```python
# ë…¸ë“œ 1
return {"aggregated_data": {"x": 1, "y": 2}}

# ë…¸ë“œ 2
return {"aggregated_data": {"y": 3, "z": 4}}

# ìµœì¢… state["aggregated_data"] = {"x": 1, "y": 3, "z": 4}
```

---

#### ì»¤ìŠ¤í…€ Reducer: `append_unique`
```python
insights: Annotated[List[str], append_unique]
```

**ë™ì‘**:
```python
# ë…¸ë“œ 1
return {"insights": ["Insight A", "Insight B"]}

# ë…¸ë“œ 2
return {"insights": ["Insight B", "Insight C"]}

# ìµœì¢… state["insights"] = ["Insight A", "Insight B", "Insight C"]
```

---

### 3. LangGraph 0.6.x ì›Œí¬í”Œë¡œìš° íŒ¨í„´

#### A. StateGraph ìƒì„±
```python
from langgraph.graph import StateGraph
from .states import SalesState
from .context import AgentContext

workflow = StateGraph(
    state_schema=SalesState,
    context_schema=AgentContext
)
```

---

#### B. ë…¸ë“œ ì •ì˜
```python
from langgraph.runtime import Runtime

async def data_collection_node(
    state: Dict[str, Any],
    runtime: Runtime
) -> Dict[str, Any]:
    # Context ì ‘ê·¼ (READ-ONLY)
    ctx = await runtime.context()
    user_id = ctx["user_id"]
    debug_mode = ctx.get("debug_mode", False)

    if debug_mode:
        logger.debug(f"Processing for user: {user_id}")

    # State ì½ê¸°
    query = state["query"]

    # ë°ì´í„° ìˆ˜ì§‘ ë¡œì§
    result = await fetch_data(query)

    # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "sql_result": [result],
        "status": "data_collected",
        "execution_step": "analysis"
    }
```

---

#### C. ë…¸ë“œ ë° ì—£ì§€ ì¶”ê°€
```python
workflow.add_node("parse_query", parse_query_node)
workflow.add_node("data_collection", data_collection_node)
workflow.add_node("analysis", analysis_node)
workflow.add_node("format_result", format_result_node)

workflow.add_edge("parse_query", "data_collection")
workflow.add_edge("data_collection", "analysis")
workflow.add_edge("analysis", "format_result")

workflow.set_entry_point("parse_query")
workflow.set_finish_point("format_result")
```

---

#### D. ì¡°ê±´ë¶€ ì—£ì§€
```python
def should_retry(state: Dict[str, Any]) -> str:
    if state.get("errors"):
        return "retry"
    return "continue"

workflow.add_conditional_edges(
    "data_collection",
    should_retry,
    {
        "retry": "parse_query",
        "continue": "analysis"
    }
)
```

---

#### E. ì‹¤í–‰
```python
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver

# ì²´í¬í¬ì¸í„° ìƒì„±
async with AsyncSqliteSaver.from_conn_string("checkpoints/agent.db") as checkpointer:
    # ì»´íŒŒì¼
    app = workflow.compile(checkpointer=checkpointer)

    # ì´ˆê¸° ìƒíƒœ
    initial_state = create_sales_initial_state(
        query="Show me monthly sales",
        period="monthly"
    )

    # ì»¨í…ìŠ¤íŠ¸
    context = create_agent_context(
        user_id="user123",
        session_id="session456",
        debug_mode=True
    )

    # ì‹¤í–‰
    config = {
        "recursion_limit": 25,
        "configurable": {"thread_id": "session456"}
    }

    result = await app.ainvoke(
        initial_state,
        config=config,
        context=context
    )

    print(result["final_report"])
```

---

### 4. ì„œë¸Œê·¸ë˜í”„ í˜¸ì¶œ

```python
from langgraph.graph import StateGraph

# ì„œë¸Œê·¸ë˜í”„ ì •ì˜
data_collection_subgraph = StateGraph(
    state_schema=DataCollectionState,
    context_schema=SubgraphContext
)
# ... ë…¸ë“œ ì¶”ê°€ ...
data_collection_app = data_collection_subgraph.compile()

# ë©”ì¸ ì—ì´ì „íŠ¸ ë…¸ë“œì—ì„œ ì„œë¸Œê·¸ë˜í”„ í˜¸ì¶œ
async def invoke_data_collection(
    state: Dict[str, Any],
    runtime: Runtime
) -> Dict[str, Any]:
    # ë¶€ëª¨ Context ê°€ì ¸ì˜¤ê¸°
    parent_ctx = await runtime.context()

    # ì„œë¸Œê·¸ë˜í”„ Context ìƒì„±
    subgraph_ctx = create_subgraph_context(
        parent_context=parent_ctx,
        parent_agent="sales_agent",
        subgraph_name="data_collection",
        suggested_tools=["sql_query"],
        db_paths={"sales_performance": "..."}
    )

    # ì„œë¸Œê·¸ë˜í”„ State ì¤€ë¹„
    subgraph_state = {
        "query_params": state["parsed_query"],
        "target_databases": ["sales_performance"],
        "collection_status": "pending",
        "errors": []
    }

    # ì„œë¸Œê·¸ë˜í”„ ì‹¤í–‰
    config = {"configurable": {"thread_id": parent_ctx["session_id"]}}
    result = await data_collection_app.ainvoke(
        subgraph_state,
        config=config,
        context=subgraph_ctx
    )

    # ê²°ê³¼ë¥¼ ë©”ì¸ Stateë¡œ ë³‘í•©
    return {
        "data_collection_result": result,
        "collected_data": result["aggregated_performance"],
        "execution_step": "analysis"
    }
```

---

## LangGraph 0.6.7 ì±—ë´‡ ê°œë°œ ê°€ì´ë“œ

### í•„ìš”í•œ ìˆ˜ì •/ì¶”ê°€ ì‚¬í•­

#### 1. `states.py`ì— `ChatbotState` ì¶”ê°€

```python
class ChatbotState(BaseState):
    """
    Chatbot State
    ëŒ€í™”í˜• ì—ì´ì „íŠ¸ë¥¼ ìœ„í•œ ìƒíƒœ ì •ì˜
    """

    # ëŒ€í™” ê´€ë ¨
    messages: Annotated[List[Dict[str, str]], add]  # ëŒ€í™” íˆìŠ¤í† ë¦¬
    current_message: Optional[str]  # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
    current_intent: Optional[str]   # í˜„ì¬ ì¸í…íŠ¸

    # ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜
    context_variables: Annotated[Dict[str, Any], merge_dicts]  # ëŒ€í™” ì»¨í…ìŠ¤íŠ¸

    # ì•¡ì…˜ ì²˜ë¦¬
    action_type: Optional[str]      # query_data, generate_document, etc.
    action_params: Optional[Dict[str, Any]]  # ì•¡ì…˜ íŒŒë¼ë¯¸í„°
    action_result: Optional[Dict[str, Any]]  # ì•¡ì…˜ ì‹¤í–‰ ê²°ê³¼

    # ì‘ë‹µ ìƒì„±
    response: Optional[str]         # ìµœì¢… ì‘ë‹µ
    response_metadata: Annotated[Dict[str, Any], merge_dicts]  # ì‘ë‹µ ë©”íƒ€ë°ì´í„°
```

---

#### 2. `context.py`ì— ì±„íŒ… ê´€ë ¨ í•„ë“œ ì¶”ê°€

```python
class AgentContext(TypedDict):
    # ... ê¸°ì¡´ í•„ë“œ ...

    # ì±„íŒ… ê´€ë ¨ ì¶”ê°€
    conversation_history: Optional[List[Dict[str, str]]]  # ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬
    user_preferences: Optional[Dict[str, Any]]            # ì‚¬ìš©ì ì„ í˜¸ë„
    active_session_data: Optional[Dict[str, Any]]         # í™œì„± ì„¸ì…˜ ë°ì´í„°
```

---

#### 3. `config.py`ì— ì±„íŒ… ì„¤ì • ì¶”ê°€

```python
# ëª¨ë¸ ì„¤ì •ì— ì¶”ê°€
DEFAULT_MODELS = {
    "intent": "gpt-4o-mini",
    "planning": "gpt-4o",
    "chatbot": "gpt-4o",           # ì¶”ê°€
}

DEFAULT_MODEL_PARAMS = {
    "intent": {"temperature": 0.3, "max_tokens": 500},
    "planning": {"temperature": 0.3, "max_tokens": 2000},
    "chatbot": {"temperature": 0.7, "max_tokens": 1500},  # ì¶”ê°€
}

# íƒ€ì„ì•„ì›ƒì— ì¶”ê°€
TIMEOUTS = {
    "agent": 30,
    "llm": 20,
    "chatbot": 60,  # ì¶”ê°€ - ëŒ€í™”í˜• ì²˜ë¦¬ëŠ” ë” ê¸´ íƒ€ì„ì•„ì›ƒ
}

# ì±„íŒ… ì „ìš© ì„¤ì • ì¶”ê°€
CHATBOT = {
    "max_conversation_history": 20,     # ìµœëŒ€ ëŒ€í™” íˆìŠ¤í† ë¦¬
    "context_window": 10,               # ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°
    "enable_memory": True,              # ë©”ëª¨ë¦¬ í™œì„±í™”
    "enable_streaming": False,          # ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
}
```

---

#### 4. ìƒˆ íŒŒì¼: `chatbot_agent.py`

```python
"""
Chatbot Agent Implementation
LangGraph 0.6.x ê¸°ë°˜ ëŒ€í™”í˜• ì—ì´ì „íŠ¸
"""

from typing import Dict, Any, Type
from langgraph.graph import StateGraph
from langgraph.runtime import Runtime
import logging

from .base_agent import BaseAgent
from .states import ChatbotState
from .context import AgentContext
from .config import Config


logger = logging.getLogger(__name__)


class ChatbotAgent(BaseAgent):
    """
    ëŒ€í™”í˜• ì—ì´ì „íŠ¸
    ì‚¬ìš©ì ë©”ì‹œì§€ â†’ ì¸í…íŠ¸ ë¶„ë¥˜ â†’ ì•¡ì…˜ ì‹¤í–‰ â†’ ì‘ë‹µ ìƒì„±
    """

    def __init__(self, agent_name: str = "chatbot", checkpoint_dir: str = None):
        super().__init__(agent_name, checkpoint_dir)

    def _get_state_schema(self) -> Type:
        """ChatbotState ì‚¬ìš©"""
        return ChatbotState

    def _build_graph(self):
        """ì±„íŒ… ì›Œí¬í”Œë¡œìš° êµ¬ì„±"""
        self.workflow = StateGraph(
            state_schema=ChatbotState,
            context_schema=AgentContext
        )

        # ë…¸ë“œ ì¶”ê°€
        self.workflow.add_node("classify_intent", self.classify_intent_node)
        self.workflow.add_node("execute_action", self.execute_action_node)
        self.workflow.add_node("generate_response", self.generate_response_node)

        # ì—£ì§€ ì •ì˜
        self.workflow.add_edge("classify_intent", "execute_action")
        self.workflow.add_edge("execute_action", "generate_response")

        # ì‹œì‘/ì¢…ë£Œì 
        self.workflow.set_entry_point("classify_intent")
        self.workflow.set_finish_point("generate_response")

    async def _validate_input(self, input_data: Dict[str, Any]) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        if "current_message" not in input_data:
            self.logger.error("Missing required field: current_message")
            return False
        return True

    # ===== ë…¸ë“œ êµ¬í˜„ =====

    async def classify_intent_node(
        self,
        state: Dict[str, Any],
        runtime: Runtime
    ) -> Dict[str, Any]:
        """ì¸í…íŠ¸ ë¶„ë¥˜ ë…¸ë“œ"""
        ctx = await runtime.context()

        message = state["current_message"]
        self.logger.info(f"Classifying intent for: {message}")

        # LLMì„ ì‚¬ìš©í•œ ì¸í…íŠ¸ ë¶„ë¥˜
        intent_config = Config.get_model_config("intent")

        # TODO: ì‹¤ì œ LLM í˜¸ì¶œ
        # intent = await classify_intent_with_llm(message, intent_config)

        # ì˜ˆì‹œ ê²°ê³¼
        intent = "query_sales_data"
        action_params = {
            "query": message,
            "period": "monthly"
        }

        return {
            "current_intent": intent,
            "action_type": intent,
            "action_params": action_params,
            "execution_step": "executing_action"
        }

    async def execute_action_node(
        self,
        state: Dict[str, Any],
        runtime: Runtime
    ) -> Dict[str, Any]:
        """ì•¡ì…˜ ì‹¤í–‰ ë…¸ë“œ"""
        ctx = await runtime.context()

        action_type = state["action_type"]
        action_params = state["action_params"]

        self.logger.info(f"Executing action: {action_type}")

        # ì•¡ì…˜ íƒ€ì…ë³„ ì²˜ë¦¬
        if action_type == "query_sales_data":
            result = await self._query_sales_data(action_params, ctx)
        elif action_type == "generate_document":
            result = await self._generate_document(action_params, ctx)
        else:
            result = {"error": f"Unknown action type: {action_type}"}

        return {
            "action_result": result,
            "execution_step": "generating_response"
        }

    async def generate_response_node(
        self,
        state: Dict[str, Any],
        runtime: Runtime
    ) -> Dict[str, Any]:
        """ì‘ë‹µ ìƒì„± ë…¸ë“œ"""
        ctx = await runtime.context()

        action_result = state["action_result"]
        current_message = state["current_message"]

        self.logger.info("Generating response")

        # LLMì„ ì‚¬ìš©í•œ ì‘ë‹µ ìƒì„±
        chatbot_config = Config.get_model_config("chatbot")

        # TODO: ì‹¤ì œ LLM í˜¸ì¶œ
        # response = await generate_response_with_llm(
        #     current_message, action_result, chatbot_config
        # )

        # ì˜ˆì‹œ ì‘ë‹µ
        response = f"Based on your query, here are the results: {action_result}"

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        new_messages = [
            {"role": "user", "content": current_message},
            {"role": "assistant", "content": response}
        ]

        return {
            "messages": new_messages,
            "response": response,
            "status": "completed",
            "execution_step": "finished"
        }

    # ===== í—¬í¼ ë©”ì„œë“œ =====

    async def _query_sales_data(
        self,
        params: Dict[str, Any],
        ctx: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ì˜ì—… ë°ì´í„° ì¿¼ë¦¬"""
        # TODO: SalesAgent í˜¸ì¶œ ë˜ëŠ” ì§ì ‘ DB ì¿¼ë¦¬
        return {"data": "Sample sales data"}

    async def _generate_document(
        self,
        params: Dict[str, Any],
        ctx: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ë¬¸ì„œ ìƒì„±"""
        # TODO: DocumentAgent í˜¸ì¶œ
        return {"document": "Sample document"}
```

---

#### 5. ì‚¬ìš© ì˜ˆì‹œ

```python
import asyncio
from core.chatbot_agent import ChatbotAgent
from core.context import create_agent_context

async def main():
    # ì—ì´ì „íŠ¸ ìƒì„±
    chatbot = ChatbotAgent()

    # ì…ë ¥ ë°ì´í„°
    input_data = {
        "current_message": "Show me monthly sales for John",
        "user_id": "user123",
        "session_id": "session456"
    }

    # ì‹¤í–‰
    result = await chatbot.execute(input_data)

    if result["status"] == "success":
        response = result["data"]["response"]
        print(f"Chatbot: {response}")
    else:
        print(f"Error: {result['error']}")

if __name__ == "__main__":
    asyncio.run(main())
```

---

### ì±„íŒ… íˆìŠ¤í† ë¦¬ ê´€ë¦¬

```python
async def get_conversation_history(session_id: str) -> List[Dict[str, str]]:
    """ì„¸ì…˜ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
    agent = ChatbotAgent()
    state = await agent.get_state(session_id)

    if state:
        return state.get("messages", [])
    return []

async def continue_conversation(
    session_id: str,
    new_message: str
) -> str:
    """ê¸°ì¡´ ì„¸ì…˜ì—ì„œ ëŒ€í™” ê³„ì†"""
    agent = ChatbotAgent()

    # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ ê°€ì ¸ì˜¤ê¸°
    history = await get_conversation_history(session_id)

    # ì…ë ¥ ë°ì´í„°
    input_data = {
        "current_message": new_message,
        "messages": history,  # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ í¬í•¨
        "user_id": "user123",
        "session_id": session_id
    }

    # ì‹¤í–‰
    result = await agent.execute(input_data)

    if result["status"] == "success":
        return result["data"]["response"]
    else:
        return f"Error: {result['error']}"
```

---

## ì£¼ì˜ì‚¬í•­

### 1. BaseAgent ë¹„í™œì„±í™”
- **ìœ„ì¹˜**: `__init__.py` ë¼ì¸ 22, 45
- **ì´ìœ **: í˜„ì¬ ì„ì‹œ ë¹„í™œì„±í™” ìƒíƒœ
- **ì˜í–¥**: `from core import BaseAgent` ì‚¬ìš© ë¶ˆê°€
- **í•´ê²°**: `from core.base_agent import BaseAgent` ì§ì ‘ ì„í¬íŠ¸

---

### 2. ContextëŠ” READ-ONLY
```python
# âŒ ì˜ëª»ëœ ì‚¬ìš©
async def node(state: Dict, runtime: Runtime) -> Dict:
    ctx = await runtime.context()
    ctx["user_id"] = "new_user"  # ì—ëŸ¬ ë°œìƒ (READ-ONLY)

# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©
async def node(state: Dict, runtime: Runtime) -> Dict:
    ctx = await runtime.context()
    user_id = ctx["user_id"]  # ì½ê¸°ë§Œ ê°€ëŠ¥
```

---

### 3. State ë¶€ë¶„ ì—…ë°ì´íŠ¸
ë…¸ë“œëŠ” **ë³€ê²½ëœ í•„ë“œë§Œ** ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

```python
# âŒ ì˜ëª»ëœ ì‚¬ìš© (ì „ì²´ State ë°˜í™˜)
async def node(state: Dict, runtime: Runtime) -> Dict:
    return state  # ëª¨ë“  í•„ë“œ ë°˜í™˜

# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš© (ë¶€ë¶„ ì—…ë°ì´íŠ¸)
async def node(state: Dict, runtime: Runtime) -> Dict:
    return {
        "status": "processing",
        "sql_result": [{"row": 1}]
    }
```

---

### 4. ì²´í¬í¬ì¸í„°ëŠ” async context manager ì‚¬ìš©
```python
# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©
async with AsyncSqliteSaver.from_conn_string(path) as checkpointer:
    app = workflow.compile(checkpointer=checkpointer)
    result = await app.ainvoke(state, config, context=context)

# âŒ ì˜ëª»ëœ ì‚¬ìš© (context manager ì—†ìŒ)
checkpointer = AsyncSqliteSaver.from_conn_string(path)
app = workflow.compile(checkpointer=checkpointer)
# ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ ë°œìƒ ê°€ëŠ¥
```

---

### 5. thread_idëŠ” session_id ì‚¬ìš©
```python
# BaseAgent.execute()ì—ì„œ ìë™ ì„¤ì • (ë¼ì¸ 195)
config["configurable"]["thread_id"] = context.get("session_id", "default")
```

---

### 6. Reducer ë™ì‘ ì´í•´
```python
# add: ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
errors: Annotated[List[str], add]
# ë…¸ë“œ1: {"errors": ["A"]} â†’ state["errors"] = ["A"]
# ë…¸ë“œ2: {"errors": ["B"]} â†’ state["errors"] = ["A", "B"]

# merge_dicts: ë”•ì…”ë„ˆë¦¬ ë³‘í•© (ë®ì–´ì“°ê¸°)
data: Annotated[Dict, merge_dicts]
# ë…¸ë“œ1: {"data": {"x": 1, "y": 2}}
# ë…¸ë“œ2: {"data": {"y": 3, "z": 4}}
# ìµœì¢…: {"x": 1, "y": 3, "z": 4}

# append_unique: ì¤‘ë³µ ì œê±° ì¶”ê°€
insights: Annotated[List[str], append_unique]
# ë…¸ë“œ1: {"insights": ["A", "B"]}
# ë…¸ë“œ2: {"insights": ["B", "C"]}
# ìµœì¢…: ["A", "B", "C"]
```

---

### 7. ì„œë¸Œê·¸ë˜í”„ í˜¸ì¶œ ì‹œ Context í•„í„°ë§
```python
# SubgraphContextëŠ” AgentContextì˜ í•„í„°ë§ëœ ì„œë¸Œì…‹
subgraph_ctx = create_subgraph_context(
    parent_context=parent_ctx,
    parent_agent="sales_agent",
    subgraph_name="data_collection"
)

# í¬í•¨ë˜ëŠ” í•„ë“œ:
# - user_id, session_id, request_id, language, debug_mode
# - parent_agent, subgraph_name
# - suggested_tools, analysis_depth, db_paths

# ì œì™¸ë˜ëŠ” í•„ë“œ:
# - api_keys, timeout_overrides, dry_run, strict_mode, max_retries
```

---

### 8. íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
```python
# Configì—ì„œ ê¸°ë³¸ê°’ ì„¤ì •
TIMEOUTS = {
    "agent": 30,
    "llm": 20,
}

# execute()ì—ì„œ íƒ€ì„ì•„ì›ƒ ì ìš©
timeout = config.get("timeout", 30)
result = await asyncio.wait_for(
    app.ainvoke(state, config, context=context),
    timeout=timeout
)
```

---

## ë¶€ë¡: íŒŒì¼ ìƒì„¸ ì •ë³´

### ë¼ì¸ ìˆ˜ ìš”ì•½
| íŒŒì¼ | ë¼ì¸ ìˆ˜ | ì£¼ìš” ë‚´ìš© |
|------|--------|----------|
| `__init__.py` | 47 | ëª¨ë“ˆ ìµìŠ¤í¬íŠ¸ |
| `base_agent.py` | 325 | BaseAgent ì¶”ìƒ í´ë˜ìŠ¤ |
| `checkpointer.py` | 94 | ì²´í¬í¬ì¸íŠ¸ ìœ í‹¸ë¦¬í‹° |
| `config.py` | 140 | ì‹œìŠ¤í…œ ì„¤ì • |
| `context.py` | 206 | Context ì •ì˜ |
| `states.py` | 267 | State ì •ì˜ |
| **í•©ê³„** | **1,079** | |

---

### ì˜ì¡´ì„±
```python
# ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from langgraph.graph import StateGraph
from langgraph.runtime import Runtime
from langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver
from langgraph.checkpoint.sqlite import SqliteSaver

# í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from typing import TypedDict, Dict, Any, List, Optional, Annotated, Type, Callable
from abc import ABC, abstractmethod
from pathlib import Path
from datetime import datetime
from operator import add
import logging
import asyncio
import uuid
import os

# í™˜ê²½ ë³€ìˆ˜
from dotenv import load_dotenv
```

---

### í™˜ê²½ ë³€ìˆ˜
```bash
# .env íŒŒì¼
LOG_LEVEL=INFO
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=...
```

---

## ë¬¸ì„œ ì •ë³´

**ì‘ì„±ì**: AI Assistant
**ì‘ì„±ì¼**: 2025-09-27
**ë²„ì „**: 1.0
**LangGraph ë²„ì „**: 0.6.7
**í”„ë¡œì íŠ¸ ê²½ë¡œ**: `C:\kdy\Projects\holmesnyangz\beta_v003\backend\service\core\`

---

**ë**