# ë¬¸ì œ í•´ê²° ê°€ì´ë“œ (Troubleshooting)

## ğŸ”§ ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë° í•´ê²° ë°©ë²•

### 1. ì„í¬íŠ¸ ì—ëŸ¬

#### ModuleNotFoundError: No module named 'chromadb'
```bash
# í•´ê²° ë°©ë²•
pip install chromadb sentence-transformers
```

#### ModuleNotFoundError: No module named 'sentence_transformers'
```bash
pip install sentence-transformers
```

#### ì „ì²´ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
cd backend/data/storage/legal_info/embedding
pip install -r requirements.txt
```

---

### 2. ê²½ë¡œ ê´€ë ¨ ì˜¤ë¥˜

#### FileNotFoundError: ì²­í‚¹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
```
FileNotFoundError: [Errno 2] No such file or directory: 'backend/data/storage/legal_info/chunked'
```

**ì›ì¸**: ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì˜ëª»ëœ ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰

**í•´ê²° ë°©ë²•**:
```bash
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰
cd C:\kdy\Projects\holmesnyangz\beta_v001
python backend/data/storage/legal_info/embedding/embed_legal_documents.py --test
```

#### FileNotFoundError: ì„ë² ë”© ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ
```
OSError: backend/models/kure_v1 not found
```

**í™•ì¸ ë°©ë²•**:
```bash
dir backend\models\kure_v1
```

**í•´ê²° ë°©ë²•**:
- ëª¨ë¸ íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°: `backend/models/kure_v1` í´ë”ì— ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”
- ê²½ë¡œê°€ ë‹¤ë¥¸ ê²½ìš°: `embed_legal_documents.py`ì˜ `MODEL_PATH` ìˆ˜ì •

---

### 3. ChromaDB ê´€ë ¨ ì˜¤ë¥˜

#### PermissionError: ChromaDB íŒŒì¼ ì ê¹€
```
PermissionError: [WinError 32] ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ íŒŒì¼ì„ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤
```

**ì›ì¸**: ChromaDBë¥¼ ì‚¬ìš© ì¤‘ì¸ ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ ì¡´ì¬

**í•´ê²° ë°©ë²•**:
```bash
# 1. ChromaDB ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
# - LangGraph ì—ì´ì „íŠ¸ ì¤‘ì§€
# - Jupyter Notebook ì»¤ë„ ì¬ì‹œì‘
# - í„°ë¯¸ë„ ì„¸ì…˜ ì¢…ë£Œ

# 2. ë‹¤ì‹œ ì‹¤í–‰
python backend/data/storage/legal_info/embedding/embed_legal_documents.py --test
```

#### ValueError: Collection already exists
```
ValueError: Collection korean_legal_documents already exists
```

**ì›ì¸**: ìŠ¤í¬ë¦½íŠ¸ ë‚´ë¶€ delete_collection ì‹¤íŒ¨

**í•´ê²° ë°©ë²•**:
```python
# ìˆ˜ë™ìœ¼ë¡œ ì»¬ë ‰ì…˜ ì‚­ì œ
import chromadb

client = chromadb.PersistentClient(path="backend/data/storage/legal_info/chroma_db")
try:
    client.delete_collection("korean_legal_documents")
    print("ì‚­ì œ ì™„ë£Œ")
except:
    print("ì»¬ë ‰ì…˜ ì—†ìŒ")
```

---

### 4. ë©”ëª¨ë¦¬ ê´€ë ¨ ì˜¤ë¥˜

#### RuntimeError: CUDA out of memory
```
RuntimeError: CUDA out of memory
```

**ì›ì¸**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡± (ëŒ€ìš©ëŸ‰ ë°°ì¹˜ ì²˜ë¦¬ ì‹œ)

**í•´ê²° ë°©ë²• 1**: batch_size ì¤„ì´ê¸°
```python
# embed_legal_documents.py ìˆ˜ì •
batch_size = 50  # ê¸°ë³¸ê°’ 100ì—ì„œ 50ìœ¼ë¡œ ë³€ê²½
```

**í•´ê²° ë°©ë²• 2**: CPU ì‚¬ìš©
```python
# embed_legal_documents.py ìˆ˜ì •
model = SentenceTransformer(str(MODEL_PATH), device='cpu')
```

#### MemoryError: ë©”ëª¨ë¦¬ ë¶€ì¡±
```
MemoryError: Unable to allocate array
```

**ì›ì¸**: ì‹œìŠ¤í…œ RAM ë¶€ì¡±

**í•´ê²° ë°©ë²•**:
- ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
- batch_sizeë¥¼ 20~30ìœ¼ë¡œ ê°ì†Œ
- ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„í•  ì‹¤í–‰ (`--category` ì˜µì…˜)

---

### 5. ì¸ì½”ë”© ì—ëŸ¬

#### UnicodeDecodeError: í•œê¸€ ì½ê¸° ì‹¤íŒ¨
```
UnicodeDecodeError: 'cp949' codec can't decode byte
```

**ì›ì¸**: Windows ê¸°ë³¸ ì¸ì½”ë”© ë¬¸ì œ

**í•´ê²° ë°©ë²•**: ìŠ¤í¬ë¦½íŠ¸ì—ì„œ `encoding='utf-8'` ëª…ì‹œ (ì´ë¯¸ ì ìš©ë¨)

#### UnicodeEncodeError: ì¶œë ¥ ì—ëŸ¬
```
UnicodeEncodeError: 'cp949' codec can't encode character
```

**ì›ì¸**: Windows ì½˜ì†” ì¶œë ¥ ì¸ì½”ë”© ë¬¸ì œ

**í•´ê²° ë°©ë²•**:
```bash
# ì½˜ì†” UTF-8 ì„¤ì •
chcp 65001
python embed_legal_documents.py --test
```

---

### 6. ì‹¤í–‰ ì†ë„ ë¬¸ì œ

#### ì„ë² ë”©ì´ ë„ˆë¬´ ëŠë¦¼ (>10ë¶„)
**ì˜ˆìƒ ì‹œê°„**: ì „ì²´ 1700ê°œ ë¬¸ì„œ = ì•½ 2ë¶„

**í™•ì¸ ì‚¬í•­**:
1. GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸
```python
import torch
print(torch.cuda.is_available())  # Trueë©´ GPU ì‚¬ìš© ê°€ëŠ¥
```

2. ëª¨ë¸ ë¡œë”© í™•ì¸
```python
model = SentenceTransformer(MODEL_PATH)
print(model.device)  # cuda:0 ë˜ëŠ” cpu
```

**í•´ê²° ë°©ë²•**:
- GPU ì‚¬ìš©: ìë™ìœ¼ë¡œ ê°ì§€ë¨
- CPUë§Œ ì‚¬ìš© ì‹œ: batch_size ì¤„ì´ê¸°

---

### 7. ê²€ì¦ ì‹¤íŒ¨

#### Unknown titleì´ ì—¬ì „íˆ ë§ìŒ (100ê°œ ì´ìƒ)
**ì˜ˆìƒ**: ì¬ì„ë² ë”© í›„ 0ê°œ

**í™•ì¸ ë°©ë²•**:
```python
# ìƒ˜í”Œ í™•ì¸
collection = chroma_client.get_collection("korean_legal_documents")
unknown = collection.get(where={"title": "Unknown"}, limit=5)
print(unknown['metadatas'])
```

**ì›ì¸ ë¶„ì„**:
- ì²­í‚¹ íŒŒì¼ ë©”íƒ€ë°ì´í„° ìì²´ê°€ ëˆ„ë½ë¨
- normalize_metadata í•¨ìˆ˜ ë¡œì§ ì˜¤ë¥˜

**í•´ê²° ë°©ë²•**:
1. ì²­í‚¹ íŒŒì¼ í™•ì¸
2. `normalize_metadata` í•¨ìˆ˜ ë””ë²„ê¹…
3. ë¡œê·¸ ì¶”ê°€í•˜ì—¬ ì–´ëŠ íŒŒì¼ì—ì„œ Unknown ë°œìƒí•˜ëŠ”ì§€ í™•ì¸

#### doc_type ë¶„í¬ê°€ ì´ìƒí•¨
**ì˜ˆìƒ ë¶„í¬**:
- ë²•ë¥ : 35-45%
- ì‹œí–‰ë ¹: 20-30%
- ì‹œí–‰ê·œì¹™: 12-20%

**í™•ì¸ ë°©ë²•**:
```python
collection = chroma_client.get_collection("korean_legal_documents")
for doc_type in ["ë²•ë¥ ", "ì‹œí–‰ë ¹", "ì‹œí–‰ê·œì¹™"]:
    results = collection.get(where={"doc_type": doc_type}, limit=10000)
    print(f"{doc_type}: {len(results['ids'])}ê°œ")
```

**ì›ì¸**: `extract_doc_type` í•¨ìˆ˜ì˜ íŒ¨í„´ ë§¤ì¹­ ì˜¤ë¥˜

**í•´ê²° ë°©ë²•**: íŒŒì¼ëª… íŒ¨í„´ í™•ì¸ í›„ í•¨ìˆ˜ ìˆ˜ì •

---

### 8. JSON íŒŒì‹± ì—ëŸ¬

#### JSONDecodeError: ì²­í‚¹ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨
```
json.decoder.JSONDecodeError: Expecting value
```

**ì›ì¸**: ì†ìƒëœ JSON íŒŒì¼ ë˜ëŠ” ë¹ˆ íŒŒì¼

**í™•ì¸ ë°©ë²•**:
```bash
# íŒŒì¼ í¬ê¸° í™•ì¸
dir backend\data\storage\legal_info\chunked\*\*.json
```

**í•´ê²° ë°©ë²•**:
- 0ë°”ì´íŠ¸ íŒŒì¼ ì œê±° ë˜ëŠ” ì¬ìƒì„±
- JSON ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€

---

### 9. í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨

#### hard_query_test_50.py ì„±ê³µë¥ ì´ ë‚®ìŒ (<50%)
**ì˜ˆìƒ**: ì¬ì„ë² ë”© í›„ 80%+ ëª©í‘œ

**í™•ì¸ ì‚¬í•­**:
1. Unknown ë¬¸ì„œ ê°œìˆ˜ (0ê°œì—¬ì•¼ í•¨)
2. ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ì‘ë™ ì—¬ë¶€
3. doc_type í•„í„°ë§ ì‘ë™ ì—¬ë¶€

**ë””ë²„ê¹… ë°©ë²•**:
```python
# íŠ¹ì • ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
from backend.app.service.tools.legal_search_tool import LegalSearchTool

tool = LegalSearchTool()
result = await tool.search("ì „ì„¸ê¸ˆ ë°˜í™˜", params={"category": "2_ì„ëŒ€ì°¨_ì „ì„¸_ì›”ì„¸"})
print(result)
```

---

### 10. ìŠ¤í¬ë¦½íŠ¸ ì¤‘ë‹¨ ì‹œ

#### KeyboardInterrupt ë˜ëŠ” ê°•ì œ ì¢…ë£Œ
**ë¬¸ì œ**:
- ê¸°ì¡´ ì»¬ë ‰ì…˜ì€ ì´ë¯¸ ì‚­ì œë¨
- ìƒˆ ì»¬ë ‰ì…˜ì€ ì¼ë¶€ë§Œ ìƒì„±ë¨

**í•´ê²° ë°©ë²•**:
```bash
# ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹¤í–‰
python backend/data/storage/legal_info/embedding/embed_legal_documents.py --full
```

---

## ğŸ” ë””ë²„ê¹… íŒ

### 1. ë¡œê·¸ ì¶”ê°€
ì„ë² ë”© ì¤‘ ë¬¸ì œ ë°œìƒ ì‹œ ë¡œê·¸ ì¶”ê°€:

```python
# normalize_metadata í•¨ìˆ˜ì— ì¶”ê°€
def normalize_metadata(raw_metadata, category, source_file, chunk_id):
    try:
        # ... ê¸°ì¡´ ì½”ë“œ ...
        return normalized
    except Exception as e:
        print(f"âŒ ë©”íƒ€ë°ì´í„° ì •ê·œí™” ì‹¤íŒ¨: {source_file}, {chunk_id}")
        print(f"   ì›ë³¸ ë©”íƒ€ë°ì´í„°: {raw_metadata}")
        print(f"   ì—ëŸ¬: {e}")
        raise
```

### 2. ë‹¨ê³„ë³„ í…ŒìŠ¤íŠ¸

```python
# 1ë‹¨ê³„: íŒŒì¼ ì½ê¸°ë§Œ
json_file = Path("chunked/2_ì„ëŒ€ì°¨_ì „ì„¸_ì›”ì„¸/ì£¼íƒì„ëŒ€ì°¨ë³´í˜¸ë²•(ë²•ë¥ )(ì œ19356í˜¸)(20230719)_chunked.json")
with open(json_file, "r", encoding="utf-8") as f:
    chunks = json.load(f)
print(f"ì´ {len(chunks)}ê°œ ì²­í¬")

# 2ë‹¨ê³„: ë©”íƒ€ë°ì´í„° ì •ê·œí™”
for chunk in chunks[:3]:  # ì²˜ìŒ 3ê°œë§Œ
    normalized = normalize_metadata(
        chunk["metadata"],
        "2_ì„ëŒ€ì°¨_ì „ì„¸_ì›”ì„¸",
        json_file.name,
        chunk["id"]
    )
    print(normalized)

# 3ë‹¨ê³„: ì„ë² ë”© ìƒì„±
model = SentenceTransformer(MODEL_PATH)
texts = [chunk["text"] for chunk in chunks[:3]]
embeddings = model.encode(texts)
print(f"ì„ë² ë”© shape: {embeddings.shape}")
```

### 3. ìƒ˜í”Œ ë°ì´í„° í™•ì¸

```python
# ì¬ì„ë² ë”© í›„ ìƒ˜í”Œ í™•ì¸
collection = chroma_client.get_collection("korean_legal_documents")

# ì²« 10ê°œ ë¬¸ì„œ
sample = collection.get(limit=10, include=["metadatas", "documents"])
for i, (doc_id, meta, text) in enumerate(zip(sample['ids'], sample['metadatas'], sample['documents']), 1):
    print(f"\n[{i}] {doc_id}")
    print(f"    title: {meta.get('title')}")
    print(f"    doc_type: {meta.get('doc_type')}")
    print(f"    text: {text[:100]}...")
```

---

## ğŸ“ ì¶”ê°€ ë„ì›€ì´ í•„ìš”í•œ ê²½ìš°

### ë¡œê·¸ íŒŒì¼ ìƒì„±
```bash
python embed_legal_documents.py --full > embedding_log.txt 2>&1
```

### ì‹œìŠ¤í…œ ì •ë³´ í™•ì¸
```bash
python --version
pip list | findstr chromadb
pip list | findstr sentence-transformers
nvidia-smi  # GPU í™•ì¸ (ìˆëŠ” ê²½ìš°)
```

### ì²´í¬ë¦¬ìŠ¤íŠ¸
- [ ] Python 3.8 ì´ìƒ ì„¤ì¹˜ë¨
- [ ] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ë¨ (chromadb, sentence-transformers)
- [ ] ì²­í‚¹ íŒŒì¼ ì¡´ì¬ (28ê°œ íŒŒì¼)
- [ ] ì„ë² ë”© ëª¨ë¸ ì¡´ì¬ (backend/models/kure_v1)
- [ ] ChromaDB ë””ë ‰í† ë¦¬ ì“°ê¸° ê¶Œí•œ ìˆìŒ
- [ ] ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ 1GB ì´ìƒ
- [ ] RAM 8GB ì´ìƒ ì—¬ìœ 
