"""
ë²•ë¥  ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸
90ê°œ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ê³  ìƒì„¸í•œ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
"""

import asyncio
import sys
import json
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List

# Path setup
current_file = Path(__file__).resolve()
backend_dir = current_file.parent.parent.parent
if str(backend_dir) not in sys.path:
    sys.path.insert(0, str(backend_dir))

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('legal_test.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


class LegalSearchTester:
    """ë²•ë¥  ê²€ìƒ‰ ëŒ€ê·œëª¨ í…ŒìŠ¤í„°"""

    def __init__(self, queries_file: str = "test_queries_100.json"):
        """ì´ˆê¸°í™”"""
        logger.info("="*80)
        logger.info("Legal Search System - Large Scale Test")
        logger.info("="*80)

        # ì¿¼ë¦¬ ë¡œë“œ
        self.queries = self._load_queries(queries_file)
        logger.info(f"Loaded {len(self.queries)} test queries")

        # LLM Context ì´ˆê¸°í™”
        try:
            from app.service_agent.core.context import create_default_llm_context
            self.llm_context = create_default_llm_context()
            logger.info(f"LLM Context initialized with API key: {self.llm_context.api_key[:10]}...")
        except Exception as e:
            logger.warning(f"LLM Context initialization failed: {e}")
            self.llm_context = None

        # SearchTeam ì´ˆê¸°í™”
        try:
            from app.service_agent.teams.search_team import SearchTeamSupervisor
            from app.service.core.separated_states import StateManager

            self.SearchTeamSupervisor = SearchTeamSupervisor
            self.StateManager = StateManager

            self.search_team = SearchTeamSupervisor(llm_context=self.llm_context)
            logger.info("SearchTeam initialized successfully with LLM support")

        except Exception as e:
            logger.error(f"Failed to initialize SearchTeam: {e}")
            raise

        # ê²°ê³¼ ì €ì¥
        self.results = []
        self.stats = {
            "total": 0,
            "success": 0,
            "failed": 0,
            "no_results": 0,
            "with_results": 0,
            "total_time": 0.0,
            "by_category": {}
        }

    def _load_queries(self, filename: str) -> List[Dict]:
        """ì¿¼ë¦¬ íŒŒì¼ ë¡œë“œ"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data["queries"]
        except Exception as e:
            logger.error(f"Failed to load queries: {e}")
            raise

    async def run_single_test(self, query_data: Dict) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        query_id = query_data["id"]
        query = query_data["query"]
        category = query_data["category"]
        expected_strategy = query_data["expected_strategy"]

        logger.info(f"\n[{query_id}/90] Testing: {query}")
        logger.info(f"  Category: {category}")
        logger.info(f"  Expected: {expected_strategy}")

        try:
            # ê³µìœ  ìƒíƒœ ìƒì„±
            shared_state = self.StateManager.create_shared_state(
                query=query,
                session_id=f"test_{query_id}"
            )

            # SearchTeam ì‹¤í–‰
            start_time = datetime.now()
            result = await self.search_team.execute(
                shared_state,
                search_scope=["legal"]
            )
            end_time = datetime.now()
            elapsed = (end_time - start_time).total_seconds()

            # ê²°ê³¼ ë¶„ì„
            success = result.get("status") == "completed"
            legal_results = result.get("legal_results", [])
            result_count = len(legal_results)

            # ë¡œê·¸ ì¶œë ¥
            logger.info(f"  Status: {result.get('status')}")
            logger.info(f"  Results: {result_count} items")
            logger.info(f"  Time: {elapsed:.2f}s")

            if legal_results:
                # ìƒìœ„ 3ê°œ ê²°ê³¼ ì¶œë ¥
                for i, item in enumerate(legal_results[:3], 1):
                    law_title = item.get('law_title', 'N/A')
                    article_number = item.get('article_number', 'N/A')
                    relevance = item.get('relevance_score', 0)
                    logger.info(f"    [{i}] {law_title} {article_number} (score: {relevance:.3f})")

            return {
                "query_id": query_id,
                "query": query,
                "category": category,
                "expected_strategy": expected_strategy,
                "status": "success" if success else "failed",
                "result_count": result_count,
                "has_results": result_count > 0,
                "elapsed_time": elapsed,
                "top_results": [
                    {
                        "law_title": r.get("law_title", ""),
                        "article_number": r.get("article_number", ""),
                        "article_title": r.get("article_title", ""),
                        "relevance_score": r.get("relevance_score", 0),
                        "content_preview": r.get("content", "")[:200]
                    }
                    for r in legal_results[:5]
                ],
                "full_result": result
            }

        except Exception as e:
            logger.error(f"  ERROR: {e}")
            return {
                "query_id": query_id,
                "query": query,
                "category": category,
                "expected_strategy": expected_strategy,
                "status": "error",
                "error": str(e),
                "result_count": 0,
                "has_results": False,
                "elapsed_time": 0,
                "top_results": []
            }

    async def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        logger.info(f"\nStarting test execution: {len(self.queries)} queries")
        logger.info("="*80)

        for query_data in self.queries:
            result = await self.run_single_test(query_data)
            self.results.append(result)

            # í†µê³„ ì—…ë°ì´íŠ¸
            self.stats["total"] += 1
            if result["status"] == "success":
                self.stats["success"] += 1
            else:
                self.stats["failed"] += 1

            if result["has_results"]:
                self.stats["with_results"] += 1
            else:
                self.stats["no_results"] += 1

            self.stats["total_time"] += result.get("elapsed_time", 0)

            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            category = result["category"]
            if category not in self.stats["by_category"]:
                self.stats["by_category"][category] = {
                    "total": 0,
                    "success": 0,
                    "with_results": 0,
                    "avg_result_count": 0,
                    "total_result_count": 0
                }

            cat_stats = self.stats["by_category"][category]
            cat_stats["total"] += 1
            if result["status"] == "success":
                cat_stats["success"] += 1
            if result["has_results"]:
                cat_stats["with_results"] += 1
            cat_stats["total_result_count"] += result["result_count"]

            # 1ì´ˆ ëŒ€ê¸° (ë¶€í•˜ ë°©ì§€)
            await asyncio.sleep(0.1)

        # í‰ê·  ê³„ì‚°
        for category, cat_stats in self.stats["by_category"].items():
            if cat_stats["total"] > 0:
                cat_stats["avg_result_count"] = cat_stats["total_result_count"] / cat_stats["total"]

        logger.info("\n" + "="*80)
        logger.info("Test Execution Completed")
        logger.info("="*80)

    def print_summary(self):
        """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("TEST SUMMARY")
        print("="*80)

        print(f"\nTotal Queries: {self.stats['total']}")
        print(f"Success: {self.stats['success']} ({self.stats['success']/self.stats['total']*100:.1f}%)")
        print(f"Failed: {self.stats['failed']}")
        print(f"With Results: {self.stats['with_results']} ({self.stats['with_results']/self.stats['total']*100:.1f}%)")
        print(f"No Results: {self.stats['no_results']}")
        print(f"Total Time: {self.stats['total_time']:.2f}s")
        print(f"Avg Time per Query: {self.stats['total_time']/self.stats['total']:.2f}s")

        print(f"\n{'='*80}")
        print("CATEGORY BREAKDOWN")
        print("="*80)

        for category, cat_stats in sorted(self.stats["by_category"].items()):
            print(f"\n[{category}]")
            print(f"  Total: {cat_stats['total']}")
            print(f"  Success: {cat_stats['success']}")
            print(f"  With Results: {cat_stats['with_results']} ({cat_stats['with_results']/cat_stats['total']*100:.1f}%)")
            print(f"  Avg Results: {cat_stats['avg_result_count']:.1f}")

    def save_report(self, output_dir: str = "reports"):
        """ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥"""
        Path(output_dir).mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{output_dir}/test_result_legal_info_{timestamp}.json"

        report = {
            "test_info": {
                "timestamp": timestamp,
                "total_queries": self.stats["total"],
                "test_duration": self.stats["total_time"],
            },
            "statistics": self.stats,
            "results": self.results
        }

        # datetime ê°ì²´ ë³€í™˜
        def convert_datetime(obj):
            if isinstance(obj, datetime):
                return obj.isoformat()
            elif isinstance(obj, dict):
                return {k: convert_datetime(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_datetime(v) for v in obj]
            return obj

        report = convert_datetime(report)

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        logger.info(f"\nReport saved: {filename}")
        print(f"\n[SAVED] Detailed report: {filename}")

        # Markdown ë¦¬í¬íŠ¸ë„ ìƒì„±
        self._save_markdown_report(output_dir, timestamp)

    def _save_markdown_report(self, output_dir: str, timestamp: str):
        """Markdown í˜•ì‹ ë¦¬í¬íŠ¸ ìƒì„±"""
        filename = f"{output_dir}/test_result_legal_info_{timestamp}.md"

        with open(filename, 'w', encoding='utf-8') as f:
            f.write("# ë²•ë¥  ì •ë³´ ê²€ìƒ‰ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸\n\n")
            f.write(f"**í…ŒìŠ¤íŠ¸ ì¼ì‹œ:** {timestamp}\n\n")
            f.write(f"**ì´ ì¿¼ë¦¬ ìˆ˜:** {self.stats['total']}\n\n")

            f.write("## ğŸ“Š ì „ì²´ í†µê³„\n\n")
            f.write(f"- ì„±ê³µ: {self.stats['success']}ê±´ ({self.stats['success']/self.stats['total']*100:.1f}%)\n")
            f.write(f"- ì‹¤íŒ¨: {self.stats['failed']}ê±´\n")
            f.write(f"- ê²°ê³¼ ìˆìŒ: {self.stats['with_results']}ê±´ ({self.stats['with_results']/self.stats['total']*100:.1f}%)\n")
            f.write(f"- ê²°ê³¼ ì—†ìŒ: {self.stats['no_results']}ê±´\n")
            f.write(f"- ì´ ì†Œìš” ì‹œê°„: {self.stats['total_time']:.2f}ì´ˆ\n")
            f.write(f"- í‰ê·  ì‘ë‹µ ì‹œê°„: {self.stats['total_time']/self.stats['total']:.2f}ì´ˆ\n\n")

            f.write("## ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ í†µê³„\n\n")
            f.write("| ì¹´í…Œê³ ë¦¬ | ì´ ì¿¼ë¦¬ | ì„±ê³µ | ê²°ê³¼ìœ¨ | í‰ê·  ê²°ê³¼ ìˆ˜ |\n")
            f.write("|---------|--------|------|--------|-------------|\n")

            for category, cat_stats in sorted(self.stats["by_category"].items()):
                success_rate = cat_stats['with_results']/cat_stats['total']*100 if cat_stats['total'] > 0 else 0
                f.write(f"| {category} | {cat_stats['total']} | {cat_stats['success']} | {success_rate:.1f}% | {cat_stats['avg_result_count']:.1f} |\n")

            f.write("\n## ğŸ” ìƒì„¸ ê²°ê³¼\n\n")

            for result in self.results:
                f.write(f"### [{result['query_id']}] {result['query']}\n\n")
                f.write(f"- **ì¹´í…Œê³ ë¦¬:** {result['category']}\n")
                f.write(f"- **ì˜ˆìƒ ì „ëµ:** {result['expected_strategy']}\n")
                f.write(f"- **ìƒíƒœ:** {result['status']}\n")
                f.write(f"- **ê²°ê³¼ ìˆ˜:** {result['result_count']}ê±´\n")
                f.write(f"- **ì†Œìš” ì‹œê°„:** {result.get('elapsed_time', 0):.2f}ì´ˆ\n\n")

                if result.get("top_results"):
                    f.write("**ìƒìœ„ ê²°ê³¼:**\n\n")
                    for i, top in enumerate(result["top_results"], 1):
                        f.write(f"{i}. **{top['law_title']} {top['article_number']}**\n")
                        if top.get('article_title'):
                            f.write(f"   - ì œëª©: {top['article_title']}\n")
                        f.write(f"   - ê´€ë ¨ë„: {top['relevance_score']:.3f}\n")
                        f.write(f"   - ë‚´ìš©: {top['content_preview']}...\n\n")
                else:
                    f.write("*ê²°ê³¼ ì—†ìŒ*\n\n")

                f.write("---\n\n")

        logger.info(f"Markdown report saved: {filename}")
        print(f"[SAVED] Markdown report: {filename}")


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        print("\n" + "="*80)
        print("Legal Information Search System - Large Scale Test")
        print("="*80)

        # Tester ì´ˆê¸°í™”
        tester = LegalSearchTester()

        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        await tester.run_all_tests()

        # ê²°ê³¼ ìš”ì•½
        tester.print_summary()

        # ë¦¬í¬íŠ¸ ì €ì¥
        tester.save_report()

        print("\n" + "="*80)
        print("Test Completed Successfully")
        print("="*80)

    except Exception as e:
        logger.error(f"Test failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
