"""
FAISS-SQLite ë§¤ì¹­ ì¢…í•© í…ŒìŠ¤íŠ¸
Phase 1: ê¸°ë³¸ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
Phase 2: 200ê°œ ì§ˆë¬¸ ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
Phase 3: í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±
"""

import sys
from pathlib import Path

backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

import sqlite3
import pickle
import json
import numpy as np
import faiss
from datetime import datetime
from collections import defaultdict
from sentence_transformers import SentenceTransformer

# Paths
FAISS_INDEX_PATH = backend_dir / "data" / "storage" / "legal_info" / "faiss_db" / "legal_documents.index"
FAISS_METADATA_PATH = backend_dir / "data" / "storage" / "legal_info" / "faiss_db" / "legal_metadata.pkl"
SQLITE_DB_PATH = backend_dir / "data" / "storage" / "legal_info" / "sqlite_db" / "legal_metadata.db"
QUESTIONS_PATH = backend_dir / "data" / "storage" / "legal_info" / "tests" / "ë¶€ë™ì‚°_ë²•ë¥ _ì˜ˆì‹œì§ˆë¬¸_200ê°œ.json"
MODEL_PATH = backend_dir / "app" / "ml_models" / "KURE_v1"

# Report paths
REPORT_DIR = backend_dir.parent / "reports" / "database"
REPORT_JSON = REPORT_DIR / f"MATCHING_TEST_RESULTS_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
REPORT_MD = REPORT_DIR / f"MATCHING_TEST_REPORT_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"


def phase1_basic_consistency():
    """Phase 1: ê¸°ë³¸ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦"""

    print("=" * 80)
    print("Phase 1: ê¸°ë³¸ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦")
    print("=" * 80)

    # 1. FAISS ë©”íƒ€ë°ì´í„° ë¡œë“œ
    print("\n[1/4] FAISS ë©”íƒ€ë°ì´í„° ë¡œë“œ ì¤‘...")
    with open(FAISS_METADATA_PATH, 'rb') as f:
        faiss_metadata = pickle.load(f)
    print(f"   âœ… FAISS ë©”íƒ€ë°ì´í„°: {len(faiss_metadata)}ê°œ")

    # 2. SQLite ì—°ê²°
    print("\n[2/4] SQLite DB ì—°ê²° ì¤‘...")
    conn = sqlite3.connect(str(SQLITE_DB_PATH))
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()

    cursor.execute("SELECT COUNT(*) as count FROM articles")
    sqlite_count = cursor.fetchone()['count']
    print(f"   âœ… SQLite ì¡°í•­: {sqlite_count}ê°œ")

    # 3. ìˆ˜ëŸ‰ ë¹„êµ
    print("\n[3/4] ë°ì´í„° ìˆ˜ëŸ‰ ë¹„êµ...")
    count_match = len(faiss_metadata) == sqlite_count

    if count_match:
        print(f"   âœ… ìˆ˜ëŸ‰ ì¼ì¹˜: {len(faiss_metadata)}ê°œ = {sqlite_count}ê°œ")
    else:
        print(f"   âŒ ìˆ˜ëŸ‰ ë¶ˆì¼ì¹˜: FAISS {len(faiss_metadata)}ê°œ vs SQLite {sqlite_count}ê°œ")

    # 4. chunk_id ë§¤ì¹­ í…ŒìŠ¤íŠ¸
    print("\n[4/4] chunk_id ê¸°ë°˜ 1:1 ë§¤ì¹­ í…ŒìŠ¤íŠ¸...")

    success_count = 0
    fail_count = 0
    failed_items = []

    for metadata in faiss_metadata:
        chunk_id = metadata.get('chunk_id', '')

        cursor.execute(
            """
            SELECT a.article_number, a.article_title, l.title as law_title
            FROM articles a
            JOIN laws l ON a.law_id = l.law_id
            WHERE a.chunk_ids LIKE ?
            """,
            (f'%"{chunk_id}"%',)
        )
        result = cursor.fetchone()

        if result:
            success_count += 1
        else:
            fail_count += 1
            if len(failed_items) < 10:
                failed_items.append({
                    'chunk_id': chunk_id,
                    'faiss_law': metadata.get('law_title', ''),
                    'faiss_article': metadata.get('article_number', '')
                })

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*80}")
    print("Phase 1 ê²°ê³¼")
    print(f"{'='*80}")
    print(f"   ì´ í…ŒìŠ¤íŠ¸: {len(faiss_metadata)}ê°œ")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ ({success_count/len(faiss_metadata)*100:.1f}%)")
    print(f"   âŒ ì‹¤íŒ¨: {fail_count}ê°œ ({fail_count/len(faiss_metadata)*100:.1f}%)")

    if success_count == len(faiss_metadata):
        print(f"\n   ğŸ‰ ì™„ë²½! ëª¨ë“  FAISS ë²¡í„°ê°€ SQLiteì™€ ë§¤ì¹­ë©ë‹ˆë‹¤!")

    # ì‹¤íŒ¨ í•­ëª© ì¶œë ¥
    if failed_items:
        print(f"\n   ì‹¤íŒ¨ í•­ëª© (ì²˜ìŒ 10ê°œ):")
        for item in failed_items:
            print(f"      - {item['chunk_id']}: {item['faiss_law']} {item['faiss_article']}")

    conn.close()

    return {
        'faiss_count': len(faiss_metadata),
        'sqlite_count': sqlite_count,
        'count_match': count_match,
        'matching_success': success_count,
        'matching_fail': fail_count,
        'matching_rate': success_count / len(faiss_metadata) * 100,
        'failed_items': failed_items
    }


def phase2_question_search(run_full_test=True):
    """Phase 2: 200ê°œ ì§ˆë¬¸ ê¸°ë°˜ ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸"""

    print("\n" + "=" * 80)
    print("Phase 2: 200ê°œ ì§ˆë¬¸ ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 80)

    # 1. ì§ˆë¬¸ íŒŒì¼ ë¡œë“œ
    print("\n[1/6] ì§ˆë¬¸ íŒŒì¼ ë¡œë“œ ì¤‘...")
    if not QUESTIONS_PATH.exists():
        print(f"   âŒ ì§ˆë¬¸ íŒŒì¼ ì—†ìŒ: {QUESTIONS_PATH}")
        return None

    with open(QUESTIONS_PATH, 'r', encoding='utf-8') as f:
        questions_data = json.load(f)

    all_questions = []
    for category in questions_data['categories']:
        for q in category['questions']:
            q['category_name'] = category['category_name']
            all_questions.append(q)

    print(f"   âœ… ì´ {len(all_questions)}ê°œ ì§ˆë¬¸ ë¡œë“œ")

    # 2. FAISS ì¸ë±ìŠ¤ ë¡œë“œ
    print("\n[2/6] FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...")
    index = faiss.read_index(str(FAISS_INDEX_PATH))

    with open(FAISS_METADATA_PATH, 'rb') as f:
        faiss_metadata = pickle.load(f)

    print(f"   âœ… FAISS ì¸ë±ìŠ¤: {index.ntotal}ê°œ ë²¡í„°")

    # 3. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
    print("\n[3/6] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
    if MODEL_PATH.exists():
        print(f"   - ê²½ë¡œ: {MODEL_PATH}")
        model = SentenceTransformer(str(MODEL_PATH))
    else:
        print(f"   âš ï¸  KURE_v1 ì—†ìŒ, ëŒ€ì²´ ëª¨ë¸ ì‚¬ìš©")
        model = SentenceTransformer('jhgan/ko-sbert-multitask')

    print(f"   âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì°¨ì›: {model.get_sentence_embedding_dimension()})")

    # 4. SQLite ì—°ê²°
    print("\n[4/6] SQLite DB ì—°ê²° ì¤‘...")
    conn = sqlite3.connect(str(SQLITE_DB_PATH))
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    print(f"   âœ… SQLite ì—°ê²° ì™„ë£Œ")

    # 5. ì§ˆë¬¸ë³„ ê²€ìƒ‰ ì‹¤í–‰
    print(f"\n[5/6] {len(all_questions)}ê°œ ì§ˆë¬¸ ê²€ìƒ‰ ì¤‘...")

    # ì¿¼ë¦¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ (hybrid_legal_search.pyì™€ ë™ì¼)
    def enhance_query_for_search(query: str) -> str:
        """ì¿¼ë¦¬ë¥¼ ë¬¸ì„œ í˜•ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ë³€í™˜"""
        legal_terms = [
            "ìê²©ì‹œí—˜", "ì‘ì‹œ", "ì¡°ê±´", "ë“±ë¡", "ì¤‘ê°œì‚¬", "ì¤‘ê°œì—…", "ê³µì¸ì¤‘ê°œì‚¬",
            "ì „ì„¸ê¸ˆ", "ì¸ìƒë¥ ", "ì„ëŒ€ì°¨", "ê³„ì•½", "ë³´ì¦ê¸ˆ", "ê°±ì‹ ", "ì„ì°¨ì¸",
            "ì„ëŒ€ì¸", "ì›”ì„¸", "ì „ì„¸", "ê³„ì•½ì„œ", "ì„¤ëª…ì˜ë¬´",
            "ì£¼íƒ", "ê³µë™ì£¼íƒ", "ì•„íŒŒíŠ¸", "ë‹¤ì„¸ëŒ€", "ë¶„ì–‘", "ì„ëŒ€ì£¼íƒ",
            "ê¸ˆì§€í–‰ìœ„", "ì†í•´ë°°ìƒ", "ê¶Œë¦¬", "ì˜ë¬´", "ë²Œì¹™", "ê³¼íƒœë£Œ",
            "ì‹ ê³ ", "í—ˆê°€", "ìŠ¹ì¸", "ê²€ì‚¬", "í™•ì¸", "ì œì¶œ"
        ]

        keywords = []
        for term in legal_terms:
            patterns = [term, f"{term}ì—", f"{term}ì˜", f"{term}ì„", f"{term}ë¥¼",
                       f"{term}ì€", f"{term}ëŠ”", f"{term}ì´", f"{term}ê°€"]
            if any(p in query for p in patterns):
                if term not in keywords:
                    keywords.append(term)

        if keywords:
            title = " ".join(keywords[:3])
            return f"{title}\n{query}"
        return query

    # ë²•ë¥  ê³„ì¸µ êµ¬ì¡° ì¬ì •ë ¬ í•¨ìˆ˜
    def rerank_by_legal_hierarchy(results, n_results=3):
        """ë²•ë¥  ê³„ì¸µ êµ¬ì¡°ë¥¼ ê³ ë ¤í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬"""
        doc_type_weights = {
            "ë²•ë¥ ": 3.0,
            "ì‹œí–‰ë ¹": 2.0,
            "ì‹œí–‰ê·œì¹™": 1.0,
            "ëŒ€ë²•ì›ê·œì¹™": 1.5,
            "ìš©ì–´ì§‘": 0.5
        }

        reranked = []
        for i, (result, dist) in enumerate(zip(results, distances[0][:len(results)])):
            doc_type = result.get('doc_type', 'ì‹œí–‰ê·œì¹™')
            similarity_score = 1.0 / (1.0 + dist)
            weight = doc_type_weights.get(doc_type, 1.0)
            final_score = similarity_score * weight

            reranked.append({
                "index": i,
                "score": final_score,
                "result": result
            })

        reranked.sort(key=lambda x: x["score"], reverse=True)
        return [item["result"] for item in reranked[:n_results]]

    results = []
    category_stats = defaultdict(lambda: {'total': 0, 'law_match': 0})
    law_frequency = defaultdict(int)
    difficulty_stats = defaultdict(lambda: {'total': 0, 'law_match': 0})

    for i, question in enumerate(all_questions):
        if (i + 1) % 20 == 0:
            print(f"   ì§„í–‰ ì¤‘: {i+1}/{len(all_questions)} ({(i+1)/len(all_questions)*100:.1f}%)")

        # â­ ì¿¼ë¦¬ ì „ì²˜ë¦¬ ì¶”ê°€
        question_text = question['question']
        enhanced_query = enhance_query_for_search(question_text)

        # ì§ˆë¬¸ ì„ë² ë”© (ì „ì²˜ë¦¬ëœ ì¿¼ë¦¬ ì‚¬ìš©)
        query_embedding = model.encode([enhanced_query], convert_to_tensor=False).astype('float32')

        # â­ FAISS ê²€ìƒ‰ (ì¬ì •ë ¬ì„ ìœ„í•´ Top 9 ê²€ìƒ‰)
        distances, indices = index.search(query_embedding, 9)

        # ì„ì‹œ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜ì§‘
        temp_results = []
        for rank, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            if idx >= len(faiss_metadata):
                continue

            meta = faiss_metadata[idx]
            chunk_id = meta.get('chunk_id', '')

            # SQLite ë§¤ì¹­
            cursor.execute(
                """
                SELECT a.article_number, a.article_title, l.title as law_title, l.doc_type
                FROM articles a
                JOIN laws l ON a.law_id = l.law_id
                WHERE a.chunk_ids LIKE ?
                """,
                (f'%"{chunk_id}"%',)
            )
            sqlite_result = cursor.fetchone()

            if sqlite_result:
                temp_results.append({
                    'rank': rank + 1,
                    'law_title': sqlite_result['law_title'],
                    'article_number': sqlite_result['article_number'],
                    'article_title': sqlite_result['article_title'],
                    'doc_type': sqlite_result['doc_type'],
                    'distance': float(dist),
                    'chunk_id': chunk_id
                })

        # â­ ë²•ë¥  ê³„ì¸µ êµ¬ì¡°ë¡œ ì¬ì •ë ¬
        search_results = rerank_by_legal_hierarchy(temp_results, n_results=3)

        # í†µê³„ ìˆ˜ì§‘
        law_matched = False
        for result in search_results:
            # ë²•ë ¹ ë¹ˆë„ ì¹´ìš´íŠ¸
            law_frequency[result['law_title']] += 1

            # related_law ë§¤ì¹­ í™•ì¸
            if question['related_law'] in result['law_title']:
                law_matched = True

        # í†µê³„ ì—…ë°ì´íŠ¸
        category_stats[question['category_name']]['total'] += 1
        if law_matched:
            category_stats[question['category_name']]['law_match'] += 1

        difficulty_stats[question['difficulty']]['total'] += 1
        if law_matched:
            difficulty_stats[question['difficulty']]['law_match'] += 1

        results.append({
            'id': question['id'],
            'question': question_text,
            'related_law': question['related_law'],
            'category': question['category_name'],
            'difficulty': question['difficulty'],
            'topic': question['topic'],
            'law_matched': law_matched,
            'search_results': search_results
        })

    print(f"   âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ")

    # 6. í†µê³„ ê³„ì‚°
    print("\n[6/6] í†µê³„ ë¶„ì„ ì¤‘...")

    total_questions = len(results)
    total_law_matches = sum(1 for r in results if r['law_matched'])
    law_match_rate = total_law_matches / total_questions * 100

    # SQLite ë§¤ì¹­ ì„±ê³µë¥ 
    total_sqlite_matches = sum(len(r['search_results']) for r in results)
    expected_sqlite_matches = total_questions * 3  # ê° ì§ˆë¬¸ë‹¹ Top 3

    print(f"   âœ… í†µê³„ ë¶„ì„ ì™„ë£Œ")

    conn.close()

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*80}")
    print("Phase 2 ê²°ê³¼")
    print(f"{'='*80}")
    print(f"   ì´ ì§ˆë¬¸: {total_questions}ê°œ")
    print(f"   âœ… related_law ì¼ì¹˜: {total_law_matches}ê°œ ({law_match_rate:.1f}%)")
    print(f"   âœ… SQLite ë§¤ì¹­: {total_sqlite_matches}/{expected_sqlite_matches}ê°œ ({total_sqlite_matches/expected_sqlite_matches*100:.1f}%)")

    print(f"\n   ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„:")
    for cat_name, stats in sorted(category_stats.items()):
        rate = stats['law_match'] / stats['total'] * 100 if stats['total'] > 0 else 0
        print(f"      - {cat_name}: {stats['law_match']}/{stats['total']} ({rate:.1f}%)")

    print(f"\n   ë‚œì´ë„ë³„ ì •í™•ë„:")
    for diff, stats in sorted(difficulty_stats.items()):
        rate = stats['law_match'] / stats['total'] * 100 if stats['total'] > 0 else 0
        print(f"      - {diff}: {stats['law_match']}/{stats['total']} ({rate:.1f}%)")

    print(f"\n   ë²•ë ¹ ê²€ìƒ‰ ë¹ˆë„ Top 10:")
    for i, (law, count) in enumerate(sorted(law_frequency.items(), key=lambda x: x[1], reverse=True)[:10], 1):
        print(f"      {i}. {law[:50]}: {count}íšŒ")

    return {
        'total_questions': total_questions,
        'law_match_count': total_law_matches,
        'law_match_rate': law_match_rate,
        'sqlite_match_count': total_sqlite_matches,
        'sqlite_match_expected': expected_sqlite_matches,
        'sqlite_match_rate': total_sqlite_matches / expected_sqlite_matches * 100,
        'category_stats': dict(category_stats),
        'difficulty_stats': dict(difficulty_stats),
        'law_frequency': dict(law_frequency),
        'detailed_results': results[:10]  # ì²˜ìŒ 10ê°œë§Œ ì €ì¥
    }


def phase3_generate_report(phase1_result, phase2_result):
    """Phase 3: í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±"""

    print("\n" + "=" * 80)
    print("Phase 3: í†µê³„ ë¦¬í¬íŠ¸ ìƒì„±")
    print("=" * 80)

    # ë¦¬í¬íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
    REPORT_DIR.mkdir(parents=True, exist_ok=True)

    # 1. JSON ë¦¬í¬íŠ¸
    print("\n[1/2] JSON ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    report_data = {
        'test_date': datetime.now().isoformat(),
        'phase1_basic_consistency': phase1_result,
        'phase2_question_search': phase2_result
    }

    with open(REPORT_JSON, 'w', encoding='utf-8') as f:
        json.dump(report_data, f, ensure_ascii=False, indent=2)

    print(f"   âœ… JSON ë¦¬í¬íŠ¸ ì €ì¥: {REPORT_JSON.name}")

    # 2. Markdown ë¦¬í¬íŠ¸
    print("\n[2/2] Markdown ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")

    md_content = f"""# FAISS-SQLite ë§¤ì¹­ í…ŒìŠ¤íŠ¸ ê²°ê³¼

**í…ŒìŠ¤íŠ¸ ì¼ì‹œ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## Phase 1: ê¸°ë³¸ ë°ì´í„° ì¼ê´€ì„± ê²€ì¦

### ë°ì´í„° ìˆ˜ëŸ‰
- FAISS ë²¡í„°: **{phase1_result['faiss_count']:,}ê°œ**
- SQLite ë ˆì½”ë“œ: **{phase1_result['sqlite_count']:,}ê°œ**
- ìˆ˜ëŸ‰ ì¼ì¹˜: **{'âœ… ì¼ì¹˜' if phase1_result['count_match'] else 'âŒ ë¶ˆì¼ì¹˜'}**

### chunk_id ë§¤ì¹­
- ì´ í…ŒìŠ¤íŠ¸: {phase1_result['faiss_count']:,}ê°œ
- âœ… ì„±ê³µ: {phase1_result['matching_success']:,}ê°œ ({phase1_result['matching_rate']:.1f}%)
- âŒ ì‹¤íŒ¨: {phase1_result['matching_fail']:,}ê°œ

**ê²°ë¡ **: {'ğŸ‰ ì™„ë²½í•œ 1:1 ë§¤ì¹­!' if phase1_result['matching_fail'] == 0 else f'âš ï¸ {phase1_result["matching_fail"]}ê°œ ë§¤ì¹­ ì‹¤íŒ¨'}

---

"""

    if phase2_result:
        md_content += f"""## Phase 2: 200ê°œ ì§ˆë¬¸ ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸

### ì „ì²´ í†µê³„
- ì´ ì§ˆë¬¸: **{phase2_result['total_questions']}ê°œ**
- related_law ì¼ì¹˜: **{phase2_result['law_match_count']}ê°œ ({phase2_result['law_match_rate']:.1f}%)**
- SQLite ë§¤ì¹­: **{phase2_result['sqlite_match_count']}/{phase2_result['sqlite_match_expected']}ê°œ ({phase2_result['sqlite_match_rate']:.1f}%)**

### ì¹´í…Œê³ ë¦¬ë³„ ì •í™•ë„

| ì¹´í…Œê³ ë¦¬ | ì§ˆë¬¸ ìˆ˜ | ì¼ì¹˜ | ì •í™•ë„ |
|---------|--------|------|--------|
"""
        for cat_name, stats in sorted(phase2_result['category_stats'].items()):
            rate = stats['law_match'] / stats['total'] * 100 if stats['total'] > 0 else 0
            md_content += f"| {cat_name} | {stats['total']} | {stats['law_match']} | {rate:.1f}% |\n"

        md_content += f"""
### ë‚œì´ë„ë³„ ì •í™•ë„

| ë‚œì´ë„ | ì§ˆë¬¸ ìˆ˜ | ì¼ì¹˜ | ì •í™•ë„ |
|--------|--------|------|--------|
"""
        for diff, stats in sorted(phase2_result['difficulty_stats'].items()):
            rate = stats['law_match'] / stats['total'] * 100 if stats['total'] > 0 else 0
            md_content += f"| {diff} | {stats['total']} | {stats['law_match']} | {rate:.1f}% |\n"

        md_content += f"""
### ë²•ë ¹ ê²€ìƒ‰ ë¹ˆë„ Top 10

| ìˆœìœ„ | ë²•ë ¹ | ê²€ìƒ‰ íšŸìˆ˜ |
|------|------|----------|
"""
        for i, (law, count) in enumerate(sorted(phase2_result['law_frequency'].items(), key=lambda x: x[1], reverse=True)[:10], 1):
            md_content += f"| {i} | {law[:50]} | {count}íšŒ |\n"

    md_content += f"""
---

## ì¢…í•© í‰ê°€

"""

    if phase1_result['matching_fail'] == 0:
        md_content += "âœ… **Phase 1**: ì™„ë²½í•œ FAISS-SQLite ë°ì´í„° ì¼ê´€ì„±\n"
    else:
        md_content += f"âš ï¸ **Phase 1**: {phase1_result['matching_fail']}ê°œ ë§¤ì¹­ ì‹¤íŒ¨\n"

    if phase2_result and phase2_result['law_match_rate'] >= 70:
        md_content += f"âœ… **Phase 2**: ìš°ìˆ˜í•œ ê²€ìƒ‰ í’ˆì§ˆ ({phase2_result['law_match_rate']:.1f}%)\n"
    elif phase2_result:
        md_content += f"âš ï¸ **Phase 2**: ê²€ìƒ‰ í’ˆì§ˆ ê°œì„  í•„ìš” ({phase2_result['law_match_rate']:.1f}%)\n"

    md_content += f"""
---

**ìƒì„± ì‹œê°**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""

    with open(REPORT_MD, 'w', encoding='utf-8') as f:
        f.write(md_content)

    print(f"   âœ… Markdown ë¦¬í¬íŠ¸ ì €ì¥: {REPORT_MD.name}")

    print(f"\n{'='*80}")
    print("Phase 3 ì™„ë£Œ")
    print(f"{'='*80}")
    print(f"   - JSON: {REPORT_JSON}")
    print(f"   - Markdown: {REPORT_MD}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""

    print("\n")
    print("â•”" + "â•" * 78 + "â•—")
    print("â•‘" + " " * 20 + "FAISS-SQLite ë§¤ì¹­ ì¢…í•© í…ŒìŠ¤íŠ¸" + " " * 28 + "â•‘")
    print("â•š" + "â•" * 78 + "â•")
    print()

    # Phase 1: ê¸°ë³¸ ì¼ê´€ì„± ê²€ì¦
    phase1_result = phase1_basic_consistency()

    # Phase 2: 200ê°œ ì§ˆë¬¸ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Phase 2ëŠ” ì•½ 5ë¶„ ì†Œìš”)")
    print("Enter: ê³„ì† ì§„í–‰ / Ctrl+C: ì¤‘ë‹¨")
    try:
        input()
        phase2_result = phase2_question_search()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        phase2_result = None

    # Phase 3: ë¦¬í¬íŠ¸ ìƒì„±
    phase3_generate_report(phase1_result, phase2_result)

    print("\n")
    print("â•”" + "â•" * 78 + "â•—")
    print("â•‘" + " " * 30 + "í…ŒìŠ¤íŠ¸ ì™„ë£Œ" + " " * 36 + "â•‘")
    print("â•š" + "â•" * 78 + "â•")
    print()

    # Exit code
    if phase1_result['matching_fail'] > 0:
        return 1

    if phase2_result and phase2_result['law_match_rate'] < 70:
        return 1

    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
